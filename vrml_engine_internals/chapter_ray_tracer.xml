<?xml version='1.0'?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.4//EN"
  "/usr/share/sgml/docbook/dtd/xml/4.4/docbookx.dtd">

<chapter id="chapter.ray_tracer">
<title>Ray-tracer rendering</title>

<!-- Source units: RayTracer, VRMLLightMap,
     SpaceFillingCurves, SphereSampling -->

<para>This chapter describes our implementation of ray-tracer, along
with some related topics.</para>

<para>We don't even try to explain here how ray-tracing algorithms work,
as this is beyond the scope of this document.
Moreover, the ray-tracer is not the most important part of our engine
right now (OpenGL real-time rendering is). This means
that while our ray-tracer has a couple of nice and unique features,
admittedly it also lacks some common and important ray-tracer features,
and it certainly doesn't even try to compete
with many other professional open-source ray-tracing engines existing.</para>

<para>Many practical details related to using our ray-tracer are mentioned
in <ulink url="https://castle-engine.io/rayhunter.php">
rayhunter documentation</ulink>. Many sample images generated by this
ray-tracer are available in the <ulink url="https://castle-engine.io/raytr_gallery.php">
rayhunter gallery</ulink>.</para>

<sect1 id="section.using_octree">
<title>Using octree</title>

<para>The basic data structure for ray-tracing is an octree based on
triangles, that is <literal>TTriangleOctree</literal> instance.
If you want to ray-trace a scene, you have to first build
such octree and pass it to a procedure that
does actual ray-tracing. Note that the quality of the octree is critical
to the speed of the ray-tracer. Fast ray-tracer requires
much deeper octree, with less items in leafs (<literal>LeafCapacity</literal>
property) than what is usually sufficient for example
for collision detection in real-time game.</para>

<para>To calculate triangles for your octree you should use the
<literal>Triangulate</literal> method of VRML geometry nodes.
Triangles enumerated by this method should be inserted into the octree.
If you use <literal>TCastleSceneCore</literal> class to load
VRML models (described in <xref linkend="section.scene" />)
you have a comfortable method <literal>CreateTriangleOctree</literal>
available that takes care of it all, returning the ready octree
for a whole scene.</para>

<para>The <literal>Triangulation</literal> method is also admittedly responsible
for some lacks in our ray-tracer. For example, ray-tracer doesn't handle
textures, because triangulation callback doesn't return texture coordinates.
Also normal vectors are not interpolated because triangulation callback
doesn't return normal vectors at the triangle corners.
This is all intended to be fixed one day, but for now ray-tracer is not
that important for our engine.</para>

</sect1>

<sect1 id="section.classic_ray_tracer">
<title>Classic deterministic ray-tracer</title>

<para>Classic Whitted-style deterministic ray-tracer is done
by <literal>TClassicRayTracer</literal> class in
<literal>RayTracer</literal> unit.</para>

<para>Point and directional lights are used, as defined by all normal
VRML light nodes. This means that only hard shadows are available.
Algorithm sends one primary ray for each image pixel.
Ray-tracing is recursive, where the ray arrives on some surface we check
rays to light sources and eventually we recursively check refracted ray
(when <literal>Material</literal> has
<literal>transparency</literal> > 0) and reflected ray
(when <literal>Material</literal> has <literal>mirror</literal> > 0).
</para>

<para>The resulting pixel color is calculated according to <ulink
  url="http://www.web3d.org/x3d/specifications/vrml/ISO-IEC-14772-VRML97/part1/concepts.html#4.14">VRML
97 lighting equations</ulink>. This is probably the most important
advantage of ray-tracer in our engine: ability to calculate
images conforming precisely to the VRML 97 lighting specification.
Actually, we modified these equations a little, but only because:</para>

<orderedlist>
  <listitem><para>I have recursive ray-tracing while VRML 97 specifies only
    local light model, without a placeholder for reflected and refracted color.
    </para></listitem>

  <listitem><para>VRML 1.0 <literal>SpotLight</literal> must be
    calculated differently, since it uses the <literal>dropOffRate</literal>
    field (a cosinus exponent) to specify spot highlight.
    While VRML 2.0 uses the <literal>beamWidth</literal> field (a constant
    spot intensity area and then a linear drop to the spot border).
    So for VRML 1.0 spot lights we use the equations analogous to
    the OpenGL lighting equations.</para></listitem>

  <listitem><para>The ambient factor is calculated taking into account that
    standard VRML 1.0 light nodes don't have the
    <literal>ambientIntensity</literal> field. Although, as an extension,
    <ulink url="https://castle-engine.io/x3d_extensions.php#ext_light_attenuation">
    our engine allows you to specify <literal>ambientIntensity</literal>
    to get VRML 2.0 behavior in VRML 1.0</ulink>.</para></listitem>
</orderedlist>

</sect1>

<sect1 id="section.path_tracer">
<title>Path-tracer</title>

<para>Done by <literal>TPathTracer</literal> class in
<literal>RayTracer</literal> unit.</para>

<para>Surface lights are used: every shape with non-zero
<literal>emissiveColor</literal> is considered a light emitter.
For each image pixel many random paths are checked and final pixel color
is the average color gathered from all paths.</para>

<para>Path length is determined by a given minimal path length and a
Russian-roulette parameter. Every path will have at least the
specified minimal length, and then Russian-roulette will be used
to terminate the path. E.g. if you set minimal path length to 3 and
Russian-roulette parameter to 0.5 then 1/2 of all paths will have length 3,
1/4 of all paths will have length 4, 1/8 of all paths will have length 5 etc.
</para>

<para>Russian-roulette makes sure that the result
is <firstterm>unbiased</firstterm>,
i.e. the expected value is the correct result (the perfect beautiful
realistic image). However, Russian-roulette introduces also
a large variance, visible as a noise on the image.
That's why forcing some minimal path length helps.
Sensible values for minimal path length are around 1 or 2. Of course,
the more the better, but it will also slow down the rendering.
You can set minimal length to 0, then Russian-roulette will always
be used to decide about path termination (expect a lot of noise on the image!).
</para>

<para>Actually our path-tracer does something more than a normal
path-tracer should: for every pixel it checks
<literal>PrimarySamplesCount</literal> of primary rays,
and then each primary ray that hits something splits into
<literal>NonPrimarySamplesCount</literal>. So in total we check
<literal>PrimarySamplesCount</literal> *
<literal>NonPrimarySamplesCount</literal> paths.
This optimization comes from the fact that there is no need to take many
<literal>PrimarySamplesCount</literal>, because all primary rays hit
more-or-less the same thing, since they have very similar direction.</para>

<para>To get really nice results path-tracer requires a different
materials description. I added
<ulink url="https://castle-engine.io/x3d_extensions.php#ext_material_phong_brdf_fields">
a couple of additional fields to <literal>Material</literal> node
to describe physical material properties (for Phong's BRDF)</ulink>.
If these fields are not specified in <literal>Material</literal> node,
path-tracer tries to calculate them
from normal material properties, although this may result in a poor-looking
materials. There's also a program <ulink url="https://castle-engine.io/kambi_mgf2inv.php">kambi_mgf2inv</ulink>
available that let's you convert MGF files to VRML 1.0 generating correct
values for these additional <literal>Material</literal> fields.</para>

<para>Shadow cache is used, this makes path-tracer a little faster.
Also you can generate the image pixels in more intelligent order
than just line-by-line: you can use Hilbert or Peano space-filling
curves. In combination with shadow cache this can make path-tracing
faster (shadow cache should hit more often). Although in practice
space-filling curves don't make any noticeable speed difference.
Undoubtedly, there are many possibilities how to improve the
speed of our path-tracer, and maybe one day space-filling curves
will come to a real use.</para>

</sect1>

<sect1 id="section.rgbe">
<title>RGBE format</title>

<para>Our ray-tracer can store images in the RGBE format.</para>

<para><firstterm>RGBE</firstterm> stands for
<firstterm>Red + Green + Blue + Exponent</firstterm>.
It's an image format developed by Greg Ward, and used e.g. by
<ulink url="http://floyd.lbl.gov/radiance/">Radiance</ulink>.
Colors in RGBE images are stored with a very good precision,
while not wasting a lot of disk space.
<firstterm>Good precision</firstterm> means
that you may be able to expose in the image some details that
were not initially visible for the human eye, e.g. by brightening
some areas. Also color components are not clamped to [0; 1] range
&mdash; each component can be any large number.
This means that even if resulting image is too bright,
and some areas look just like white stains, you can always
correct the image by darkening it or applying gamma correction etc.
This is especially important for images generated by path-tracer.</para>

<para>You can process RGBE images using various Radiance programs.
You can also use RGBE images in all my programs,
for example you can view them using
<ulink url="https://castle-engine.io/glviewimage.php">
glViewImage</ulink> and you can use them as textures on VRML
models.</para>

</sect1>

<sect1 id="section.generating_light_maps">
<title>Generating light maps</title>

<para>This is a feature closely related to ray-tracer routines,
although it doesn't actually involve any recursive ray-tracing.
The idea comes from the realization that we already have a means to calculate
light contribution on a given point in a scene, including checking
what lights are blocked on this point. So we can use these methods to calculate
lighting on some surface <emphasis>independent
of the camera (player) position</emphasis>.
All it takes is just to remove from lighting equations
all components related to camera, which means just removing
the specular component of lighting equation. We can
do it even for any point on a scene (not necessarily a point
that is actually part of any scene geometry), as long as we will
provide material properties that should be assumed by calculation.
</para>

<para>What do we get by this? We get the ability to generate
textures that contain accumulated effect of all lights shining
on given surface. This includes shadows. We can use such texture
on a surface to get already precomputed lighting
<emphasis>with shadows</emphasis>. Of course, the trick will
only work as long as lights are static in the scene and it's not
a problem to remove specular component for given surface.
And remember to make the texture large enough &mdash; otherwise
user will see that the shadows on the wall are pixelated and
the whole nice effect will be gone.</para>

<para>I used this trick to generate ground texture for my toy
<ulink url="https://castle-engine.io/lets_take_a_walk.php">
lets_take_a_walk</ulink>. Initially I had this model:</para>

<!-- Workaround for FOP: keeping figure title+content together problem. -->
<?page-break?>

<para role="para_with_larger_screen_mini">
<figure>
  <title>lets_take_a_walk scene, side view</title>
  <mediaobject>
  <imageobject role="html">
    <imagedata format="PNG"
      fileref="images/lets_take_a_walk_screen_side_no_tex_mini.png" />
  </imageobject>
  <imageobject role="fo">
    <imagedata format="PNG"
      fileref="images/lets_take_a_walk_screen_side_no_tex.png"
      width="4in" contentwidth="4in" />
  </imageobject>
  <imageobject role="dblatex">
    <imagedata format="EPS"
      fileref="images/lets_take_a_walk_screen_side_no_tex.eps"
      width="4in" contentwidth="4in" />
  </imageobject>
  </mediaobject>
</figure>
</para>

<para role="para_with_larger_screen_mini">
<figure>
  <title>lets_take_a_walk scene, top view</title>
  <mediaobject>
  <imageobject role="html">
    <imagedata format="PNG"
      fileref="images/lets_take_a_walk_screen_top_no_tex_mini.png" />
  </imageobject>
  <imageobject role="fo">
    <imagedata format="PNG"
      fileref="images/lets_take_a_walk_screen_top_no_tex.png"
      width="4in" contentwidth="4in" />
  </imageobject>
  <imageobject role="dblatex">
    <imagedata format="EPS"
      fileref="images/lets_take_a_walk_screen_top_no_tex.eps"
      width="4in" contentwidth="4in" />
  </imageobject>
  </mediaobject>
</figure>
</para>

<para>Using our trick I generated this texture for the ground.
Note how the texture includes shadows of all scene objects.
And note how the upper-right part of the texture has a nice brighter area.
Our OpenGL rendering above didn't show this brighter place, because the ground
geometry is poorly triangulated. So OpenGL rendering hit again the problems
with Gouraud shading discussed in detail earlier in
<xref linkend="section.triangulating" />.
It's a quite large texture (1024 x 1024 pixels), but any decent OpenGL
implementation should be able to handle it without any problems.
In case of problems, I would just split it to a couple of smaller
pieces.</para>

<para role="para_with_larger_screen_mini">
<figure>
  <title>Generated ground texture</title>
  <mediaobject>
  <imageobject role="html">
    <imagedata format="PNG"
      fileref="images/base_shadowed_mini.png" />
  </imageobject>
  <imageobject role="fo">
    <imagedata format="PNG"
      fileref="images/base_shadowed.png"
      width="4in" contentwidth="4in" />
  </imageobject>
  <imageobject role="dblatex">
    <imagedata format="EPS"
      fileref="images/base_shadowed.eps"
      width="4in" contentwidth="4in" />
  </imageobject>
  </mediaobject>
</figure>
</para>

<para>Finally, resulting model with a ground texture:</para>

<para role="para_with_larger_screen_mini">
<figure>
  <title>lets_take_a_walk scene, with ground texture. Side view</title>
  <mediaobject>
  <imageobject role="html">
    <imagedata format="PNG"
      fileref="images/lets_take_a_walk_screen_side_tex_mini.png" />
  </imageobject>
  <imageobject role="fo">
    <imagedata format="PNG"
      fileref="images/lets_take_a_walk_screen_side_tex.png"
      width="4in" contentwidth="4in" />
  </imageobject>
  <imageobject role="dblatex">
    <imagedata format="EPS"
      fileref="images/lets_take_a_walk_screen_side_tex.eps"
      width="4in" contentwidth="4in" />
  </imageobject>
  </mediaobject>
</figure>
</para>

<para role="para_with_larger_screen_mini">
<figure>
  <title>lets_take_a_walk scene, with ground texture. Top view.</title>
  <mediaobject>
  <imageobject role="html">
    <imagedata format="PNG"
      fileref="images/lets_take_a_walk_screen_top_tex_mini.png" />
  </imageobject>
  <imageobject role="fo">
    <imagedata format="PNG"
      fileref="images/lets_take_a_walk_screen_top_tex.png"
      width="4in" contentwidth="4in" />
  </imageobject>
  <imageobject role="dblatex">
    <imagedata format="EPS"
      fileref="images/lets_take_a_walk_screen_top_tex.eps"
      width="4in" contentwidth="4in" />
  </imageobject>
  </mediaobject>
</figure>
</para>

<para>Such textures may be generated by the
<filename>gen_light_map</filename> program included in the
<filename>castle_game_engine/examples/vrml/tools/gen_light_map.lpr</filename>
file in our engine source code. The underlying unit responsible
for all actual work is called <literal>VRMLLightMap</literal>.
<filename>lets_take_a_walk</filename> source code is available too,
so you can see there an example how the <filename>gen_light_map</filename>
program may be called.</para>

</sect1>

</chapter>

<!--
  Local Variables:
  ispell-local-dictionary: "american"
  End:
-->