<?xml version='1.0'?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
  "/usr/share/sgml/docbook/dtd/xml/4.5/docbookx.dtd" [
<!-- C++ with zero-width no-break space character, to avoid breaking it
     into two lines (C+ and +). -->
<!ENTITY cpp "C&#xFEFF;+&#xFEFF;+" >
]>

<!--
  Offline version of this DTD (as installed from Debian testing package) is
  "/usr/share/sgml/docbook/dtd/xml/4.5/docbookx.dtd"
  Online version of this DTD is
  "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd"
-->

<book>

<bookinfo>
  <title>Compositing Shaders in X3D</title>
  <author>
    <firstname>Michalis</firstname>
    <surname>Kamburelis</surname>
  </author>
  <copyright>
    <year>2011</year>
    <holder>Michalis Kamburelis</holder>
  </copyright>
  <legalnotice><para>You can redistribute and/or modify
    this document under the terms of the
    <ulink url="http://www.gnu.org/licenses/gpl.html">GNU General Public
    License</ulink> as published by
    the Free Software Foundation; either version 2 of the License, or
    (at your option) any later version.</para>
  </legalnotice>
</bookinfo>

<!-- TODO: Title page, with above <bookinfo>,
  and "Ph.D. thesis" text,
  and Institute of Computer Science, University of WrocÅ‚aw, Poland
  and promotor,
  and maybe some image?
  add links to my pages (castle-eng and ~michalis)
-->

<preface id="abstract">
<title>Abstract</title>

<para>We present a new approach for implementing effects using the GPU shading languages.
Our effects seamlessly cooperate with each other and with
the shaders used internally by the 3D application.
Thus the effects are reusable, work in various combinations
and under all lighting and texture conditions.
This makes the GPU shaders more useful for 3D content authors.</para>

<!-- TODO: clumsy wording? -->
<para>Our approach may also be used to integrate internal effects
inside a 3D renderer. Modern renderers need to combine many effects,
like lighting, bump mapping and shadow maps.
As such, it becomes important to develop all these internal effects easily and separately.</para>
<!--
As modern 3D renderers have a number of built-in internal effects
available (like )
This makes the implementation of 3D renderers simpler and cleaner,
as many internal effects
become more independent.</para>
-->

<para>We have designed our effects to fit naturally in 3D scene graph formats,
in particular we present a number of extensions to the X3D standard.
Our extensions nicely integrate shader effects with X3D
concepts like shapes, groups, light sources and textures.
</para>

</preface>

<chapter id="chapter.overview">
<title>Overview</title>

<para>X3D <xref linkend="bib.x3d" /> is an open standard for representing interactive 3D models,
with many advanced graphic features.
</para>

<para>The X3D <emphasis>Programmable shaders component</emphasis> <xref linkend="bib.x3d_shaders" />
(part of the X3D standard) defines how <emphasis>shaders</emphasis> can be assigned
to particular shapes. <!-- and how they interact with other X3D features. -->
<emphasis>Shaders</emphasis> are programs usually executed on the graphic processor unit
(GPU). They control the per-vertex and per-pixel processing,
for example summing the lights contribution
and mixing the texture colors. The authors
can create and assign shaders to shapes, which makes
a myriad of interesting graphic effects possible in X3D models.
</para>

<para>The shaders designed using the standard nodes
<emphasis>replace</emphasis> the normal rendering functionality, not <emphasis>enhance</emphasis> it.
This reflects the underlying API, like OpenGL or Direct3D.
The 3D libraries, in turn, follow the hardware idea that shader code
should be a complete and optimized program
designed for rendering a particular shape.
</para>

<para>We argue that a different approach is needed in many situations.
Authors usually would like to keep the normal rendering features working
and only add their own effects. The 3D renderer
implementation usually already has an extensive internal shaders system
and the authors want to depend on these internal shaders
to do the common job.
</para>

<para>As an example, consider this simplified lighting equation:</para>

<informalequation>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="formulas/1.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="SVG" fileref="formulas/1.svg" /> </imageobject>
  </mediaobject>
</informalequation>

<para>
<!--
The <emphasis>shadow</emphasis> function returns values in the [0..1] range,
scaling the light color. If the object is not in the shadow, it returns 1.
The <emphasis>normal</emphasis> function returns a normal vector at given point.
-->
Different effects want to change various parts of this equation,
without touching the others.
For example, the <emphasis>shadow</emphasis> function may check a shadow map pixel,
or (when shadow map is not available) always return 1.
The <emphasis>normal</emphasis> function may take the vector straight from
the geometry description, or calculate it using a texture value (classic bump mapping).
See <xref linkend="figure.bump_mapping_shadows" />.
The <emphasis>light_color</emphasis> function may be replaced to use different
lighting models (Phong, Ward, Cook-Torrance and so on).
Sometimes it makes sense to change these functions
for all the light sources and sometimes only a specific light source
should behave differently.
Our approach allows you to do everything mentioned here.
<!--
by inserting a piece
of custom shader code into a calculation of a particular function.
on a particular object.
-->
</para>

<para role="figure_2_column">
<figure id="figure.bump_mapping_shadows">
  <title>Japanese shrine model with more and more effects applied.
The model is based on <ulink url="http://opengameart.org/content/shrine-shinto-japan"/>.</title>
  <titleabbrev>Japanese shrine model with more and more effects applied.
</titleabbrev>

<informaltable frame="none">
  <tgroup cols="2" align="center">
  <colspec colnum='1' colname='col1' colwidth='1*'/>
  <colspec colnum='2' colname='col2' colwidth='1*'/>

  <tbody>
    <row><entry>
      <mediaobject>
      <imageobject role="html"> <imagedata format="PNG" fileref="images/rhan_shrine_0.png" /> </imageobject>
      <imageobject role="fo">   <imagedata format="PNG" fileref="images/rhan_shrine_0.png" width="2.7in" contentwidth="2.7in" /> </imageobject>
      </mediaobject>
      No effects.
    </entry>
    <entry>
      <mediaobject>
      <imageobject role="html"> <imagedata format="PNG" fileref="images/rhan_shrine_1_per_pixel_lighting.png" /> </imageobject>
      <imageobject role="fo">   <imagedata format="PNG" fileref="images/rhan_shrine_1_per_pixel_lighting.png" width="2.7in" contentwidth="2.7in" /> </imageobject>
      </mediaobject>
      Phong shading (per-pixel lighting).
    </entry></row>
    <row><entry>
      <mediaobject>
      <imageobject role="html"> <imagedata format="PNG" fileref="images/rhan_shrine_2_bump_mapping.png" /> </imageobject>
      <imageobject role="fo">   <imagedata format="PNG" fileref="images/rhan_shrine_2_bump_mapping.png" width="2.7in" contentwidth="2.7in" /> </imageobject>
      </mediaobject>
      Bump mapping.
    </entry>
    <entry>
      <mediaobject>
      <imageobject role="html"> <imagedata format="PNG" fileref="images/rhan_shrine_3_shadow_1st.png" /> </imageobject>
      <imageobject role="fo">   <imagedata format="PNG" fileref="images/rhan_shrine_3_shadow_1st.png" width="2.7in" contentwidth="2.7in" /> </imageobject>
      </mediaobject>
      1st shadow map.
    </entry></row>
    <row><entry>
      <mediaobject>
      <imageobject role="html"> <imagedata format="PNG" fileref="images/rhan_shrine_4_shadow_2nd.png" /> </imageobject>
      <imageobject role="fo">   <imagedata format="PNG" fileref="images/rhan_shrine_4_shadow_2nd.png" width="2.7in" contentwidth="2.7in" /> </imageobject>
      </mediaobject>
      2nd shadow map.
    </entry>
    <entry>
      <mediaobject>
      <imageobject role="html"> <imagedata format="PNG" fileref="images/rhan_shrine_5_everything.png" /> </imageobject>
      <imageobject role="fo">   <imagedata format="PNG" fileref="images/rhan_shrine_5_everything.png" width="2.7in" contentwidth="2.7in" /> </imageobject>
      </mediaobject>
      Both shadow maps.
    </entry></row>
  </tbody>
  </tgroup>
</informaltable>
</figure>
</para>

<para>We present a system for creating effects by essentially compositing
pieces of a shader code. All the effects defined this way effortlessly
cooperate and can be combined with each other and with application internal
shaders. This makes shader programs:</para>

<orderedlist>
  <listitem><para>Much easier to create. We can jump straight into the implementation
    of our imagined algorithm in the shader.
    We are only interested in modifying the relevant shader calculation
    parameter. We do not need to care about the rest of the shader.</para></listitem>

  <listitem><para>Much more powerful. Our effect
    immediately cooperates with absolutely every normal feature of X3D rendering.
    This makes the implemented effect useful for a wide range of real uses,
    not only for a particular situation or a particular model (as it often happens
    with specialized shader code).
    All X3D light sources, textures, even other shader effects,
    are correctly applied.</para></listitem>
</orderedlist>

<para>It is important that we still keep
the full power of a chosen GPU shading language.
We deliberately do not try to invent here a new language, or wrap existing
language in some cumbersome limitations.
This is most flexible for authors,
and it also allows an easy implementation &mdash; there is no need for any complex
shading language processing inside the application.</para>

</chapter>

<chapter id="chapter.previous_work">
<title>Motivation and previous work</title>

<para>The most popular real-time shading languages right now are
OpenGL <literal>GLSL</literal> <xref linkend="bib.glsl" />,
NVidia <literal>Cg</literal> <xref linkend="bib.cg" /> and
Direct 3D <literal>HLSL</literal> <xref linkend="bib.hlsl" />.
They do not provide a ready solution for connecting shaders from independent sources.
The <literal>CgFX</literal> and HLSL <literal>.fx</literal> files encapsulate shading language code
in <emphasis>techniques</emphasis> (for various graphic card capabilities)
and within a single technique specify operations for each rendering pass.
In neither case can we simply connect multiple shader source code files
and expect the result to be a valid program.</para>

<para>The X3D <emphasis>Programmable shaders component</emphasis> <xref linkend="bib.x3d_shaders" />
makes the three shading languages mentioned above available to X3D authors.
Complete shader code may be assigned to specific shapes.
Although it does not offer any way of compositing shader effects,
<!--
the point of this component
is to expose functionality that maps straightforward to graphic APIs like OpenGL.
-->
this component is still an important base for our work. It defines
how to comfortably keep shader code inside X3D nodes. It also shows
how to pass uniform values (including textures) to the shaders.</para>

<para>An old solution to combine effects, used even before the shading languages,
is a multi-pass rendering. Each rendering pass adds or multiplies
to the buffer contents, adding a layer with desired effect.
However, this is expensive &mdash; in each pass we usually have to repeat
some work, at least transforming and clipping the geometry.
It is also not flexible &mdash; we can only modify
the complete result of the previous pass.
In our work, we want to allow a single rendering pass to be as
powerful as it can.
Arranging shader functions in a pipeline has similar disadvantages
as multi-pass rendering, except there's no speed penalty in this case.</para>

<para>Common approach for writing a flexible shader code is to create
a library of functions and allow the author to choose and compose them
in a final shader to achieve the desired look. But this approach is very limited,
as we cannot modify a particular calculation part without
replicating the algorithm outside of this calculation.
For example, if we want to scale the light contribution by a shadow function,
we will have to also replicate the code iterating over the light sources.</para>

<!--
<para>Another common solution is to arrange shaders in a pipeline, where one
shader processes the result of another. This can be visualized as
layers of materials, where each layer modifies the previous
color. It is actually similar to a multi-pass rendering approach,
except we do not lose speed on repeating the geometry transformation work.
Still it suffers from the same limitations, as we cannot change
the calculation within an existing layer, without replicating the whole
algorithm of this layer. </para>
-->

<!-- (see also http://groups.google.com/group/blendertorenderman/browse_thread/thread/aaf07831b91be9db?pli=1 , confirms my findings) -->

<para>Sh (<ulink url="http://libsh.org/" />, <xref linkend="bib.sh" />)
allows writing shader code (that can run on GPU) directly inside a
&cpp; program.
For this, Sh extends the &cpp; language (through &cpp;
operator overloading and macros tricks).
It allows an excellent
integration between &cpp; code and shaders, hiding the ugly details of
passing variables between normal code (that executes on CPU) and
shader code (that usually executes on GPU). We can use
object-oriented concepts to create a general shader that can
later be extended, for example by overriding virtual
methods. However, this is a solution closely coupled with &cpp;. It's
suitable if we have a 3D engine in &cpp;, we want to use it in
our own &cpp; program and extend its shaders. Our solution is simpler,
treating shader effects as part of the 3D content and can
be integrated into a renderer regardless of its programming language.
We do not need a &cpp; compiler to generate a final GPU shader
and users do not need to be familiar with &cpp;.</para>

<para>OGRE (<ulink url="http://www.ogre3d.org/" />), an open-source 3D engine written in &cpp;, has a system
for adding shader extensions (see <xref linkend="bib.ogre_shader" />). Its idea is similar
to our system (enhance the built-in shaders with our own effects),
however the whole job of combining a shader is done by operating
on particular shader by &cpp; code. The developer has to code
the logic deciding which shaders are extended and most of the specification
about how the extension is called is done in the &cpp; code.
This has the nice advantage of being able to encapsulate some fixed-function
features as well, however the whole system must be carefully controlled by
the &cpp; code.
In our approach, we allow the authors to write direct shading
language code quickly and the integration is built inside appropriate X3D nodes.</para>

<para>AnySL <xref linkend="bib.anysl" /> allows to integrate internal renderer shaders
with user shaders, by introducing a new shader language.
<!-- TODO: use this, uncomment
  This has
  advantages (hides the differences between GPU shading languages like
  <literal>GLSL</literal> and <literal>HLSL</literal>), but also
  On the other hand, we do not introduce
  a new shader language, which is both an advantage (easy implementation,
  easier to learn) and disadvantage (we do not hide differences e.g. between
  ).
  We strive to do something more and allow effortless
  integration between many user shaders.

  We also try to be simpler as we do not
  introduce any new shading language. On the other hand, the disadvantage
  of our approach is that we do not hide the differences between various shading languages.
  User effects have to be implemented in the same GPU shading language
  that is used by the renderer.
-->
</para>

<para>Spark <xref linkend="bib.spark" /> is a recent work presenting a new language to develop
composable shaders for GPU.</para>

<para><xref linkend="bib.web3d2010.declarativeshader" /> presents a declarative approach
to an advanced shader in X3D. However, it only allows a fixed set
of functionality, kind of an <emphasis>advanced and enhanced material</emphasis>.
It does not expose any shader functionality to the authors.
It merely allows the authors to use some advanced algorithms that in practice
will be usually implemented by shaders inside the application.
</para>

<para>At the end, we would like to mention a solution from a completely
different domain, that is surprisingly similar to ours in some ways.
Drupal (<ulink url="http://drupal.org/" />),
an open-source CMS system written in PHP,
has a very nice system of modules. Each module
can extend the functionality of the base system (or other module)
by implementing a <emphasis>hook</emphasis>, which is just a normal PHP function
with a special name and appropriate set of parameters. Modules can also define
their own hooks (for use by other modules) and invoke them when appropriate.
This creates a system where it's trivially easy to define new hooks
and to use existing hooks.
Many modules can implement the same hook and cooperate without any problems.
The whole hook system is defined completely in PHP, as it's a scripting
language and we can query the list of loaded functions by name,
and call function by its name.
Drupal approach is quite similar to our
core idea of combining effects. Our effects are similar to
Drupal's modules and our <quote>plugs</quote> are analogous to Drupal hooks.</para>

<para>Our effects can define functions with special names to enhance
the standard shader behavior, just like Drupal modules can define functions
to act on an event from another module.
We can also define new plugs, for other effects to use.
Of course we also have some special problems
(shading language is quite far from a scripting language,
so calling the plugs must be implemented by text replacements)
and some special opportunities (we can define effects at
the appropriate nodes of X3D, like textures and lights sources,
as we do not want to throw all the effects in one bag).</para>

<!--
  OpenSceneGraph:
  http://www.openscenegraph.org/projects/osg/wiki/Support/Tutorials/ShadersParameters
  http://www.openscenegraph.org/projects/osg/wiki/Support/Tutorials/ShadersIntroduction
  http://mew.cx/osg_glsl_july2005.pdf
  I see no way to connect shaders?

  Irrlight &mdash; also no way to connect shaders?

  Blender Game Engine: no way to connect shaders, Python code can
  set the final (complete) shader source only?
  http://download.blender.org/documentation/GE/Blender.htm
  http://www.blender.org/development/release-logs/blender-248/realtime-glsl-materials/
  See also source, inside source/gameengine/:
  ./Ketsji/BL_Shader.h
  ./Ketsji/BL_Shader.cpp
  ./Ketsji/BL_BlenderShader.h
  ./Ketsji/BL_BlenderShader.cpp
-->

</chapter>

<chapter id="chapter.plugs">
<title>Extending the shaders with plugs</title>

<para>The core idea of our approach is that the base shader code defines
points where calls to user-defined functions may be inserted. We call
these places <emphasis>plugs</emphasis>, as they act like sockets where logic
may be added. Each plug has a name and a given set of parameters.
The effects can use special function names, starting with <literal>PLUG_</literal>
and followed by the plug name. These declarations will be found
and the renderer will insert appropriate calls to them from the base shader.</para>

<para>A trivial example of an effect that makes colors two times brighter
is below. This is a complete X3D file, so you can save
it as <literal>test.x3dv</literal> and open with any tool supporting our
extensions, like <literal>view3dscene</literal>.</para>

<screen>#X3D V3.2 utf8
PROFILE Interchange
Shape {
  appearance Appearance {
    material Material { }
<emphasis role="bold">    effects Effect {
      language "GLSL"
      parts EffectPart {
        type "FRAGMENT"
        url "data:text/plain,
        <phrase role="italic">void PLUG_texture_apply(
          inout vec4 fragment_color,
          const in vec3 normal)
        {
          fragment_color.rgb *= 2.0;
        }</phrase>"
      }
    }</emphasis>
  }
  geometry Sphere { }
}
</screen>

<para>Our extensions to X3D are marked with the bold font in the example above.
The GLSL code inside our extensions is marked with the italic font.
<!--
GLSL function names starting with <literal>PLUG_</literal> are special,
they will be automatically called at the appropriate place with appropriate
parameters from the final (automatically generated and used) shader.
-->
The special GLSL function name <literal>PLUG_texture_apply</literal>
indicates that we use the <literal>texture_apply</literal> plug.
This particular plug is called right after applying the textures,
and is the simplest way to <quote>just modify the pixel color</quote>.
<!--
The <literal>texture_apply</literal> plug in
the renderer internal shader. This particular plug,
the <literal>PLUG_texture_apply</literal>, is called after the normal texture colors
are applied, but before the alpha test and is a usual place
-->
<literal>fragment_color</literal> is an <literal>inout</literal> parameter, by modifying it
we modify the color that will be displayed on the screen.</para>

<para>A reference of all the plugs available in our implementation
is on <ulink url="http://castle-engine.sourceforge.net/compositing_shaders.php" />.
For each plug, like this <literal>PLUG_texture_apply</literal>,
we define a list of parameters
<!-- (they have to be declared exactly the same in an effect), -->
and when it is called.</para>

<para>Many usage scenarios are possible:</para>

<orderedlist>
  <listitem><para>The <literal>Effect</literal> nodes may use plug names
    defined inside the renderer internal shaders. This is the most usual case.
    It allows the authors to extend or override a particular shading parameter.</para></listitem>

  <listitem><para>The <literal>Effect</literal> nodes may also use the plug names defined
    in the previous <literal>Effect</literal> nodes on the same shape.
    It is trivially easy (just add a <quote>magic</quote> comment) to define
    plugs in your own shader code. This way your own effects
    can be customized.</para></listitem>

  <listitem><para>Inside the renderer implementation, the same approach can be used
    to implement some internal effects.
    We have reimplemented many internal effects of our engine,
    like the fog, shadow maps (see our shadow mapping extensions for X3D <xref linkend="bib.castleengine.shadowmaps" />)
    and the bump mapping to use our <quote>plugs</quote> approach.
    This made their implementation very clean, short
    and nicely separated from each other.
    It also proves that
    the authors have the power to implement similar effects easily by themselves.
    </para>

<!--
    <para>
    without any traditional hassles. For example, bump mapping can be
    achieved using standard <literal>ComposedShader</literal> as well,
    but then you have to write all this <quote>boilerplate</quote> code to also deal
    with all the possible lighting and textures configurations.
    Well, the renderer is still useful to calculate nice tangent vectors,
    although an authoring program could generate GLSL attributes for them as well.</para>

    <para>
    Same thing with shadow maps, they only plug to the <literal>light_scale</literal>
    calculation of appropriate light.</para>
-->
    </listitem>
</orderedlist>

<para>Actually, there are even more possibilities.
We have been talking above about the <quote>renderer internal shaders</quote>,
but the truth is a little more flexible.
When you place a standard shader node
(like a <literal>ComposedShader</literal> node for GLSL shaders) on the
<literal>Appearance.shaders</literal> list,
then it replaces the internal renderer shaders.
If you define the same (or compatible) plugs inside your shader,
then the internal renderer effects are even added to your own
shader. Of course user effects are added to your shader too.
This way even the standard X3D shader nodes become more flexible.
Note that if you do not define any plugs inside your <literal>ComposedShader</literal> node,
it continues to function as before &mdash; no effects
will be added.</para>

<section id="section.effect_node">
<title>Effect node</title>

<para>New <literal>Effect</literal> node holds information about
the source code and uniform values specific to a given effect.
The node specification below follows the style of
the X3D specification <xref linkend="bib.x3d" />.</para>

<screen><phrase role="underline">Effect : X3DChildNode</phrase>

SFString [] <emphasis role="bold">language</emphasis> ""
  # Language like "GLSL", "CG", "HLSL".
  # This effect will be used
  # only when the base renderer shader
  # uses the same language.

SFBool [in,out] <emphasis role="bold">enabled</emphasis> TRUE
  # Easily turn on/off the effect.
  # You could also remove/add the node
  # from the scene, but often toggling
  # this field is easier for scripts.

MFNode [] <emphasis role="bold">parts</emphasis> [] # EffectPart
  # Source code of the effect.

# A number of uniform values may also be
# declared inside this node.
</screen>

<para>Inside the <literal>Effect</literal> node a number of uniform values may be defined,
passing any X3D value to the shader. Examples include passing
current world time or a particular texture to the shader.
Uniform values are declared exactly like described in the standard
X3D <emphasis>Programmable shaders</emphasis> component <xref linkend="bib.x3d_shaders" />.</para>

<para>The effect source code is split into a number of parts:</para>

<screen><phrase role="underline">EffectPart : X3DNode, X3DUrlObject</phrase>

SFString [] <emphasis role="bold">type</emphasis> "VERTEX"
  # Like ShaderPart.type:
  # allowed values are
  # FRAGMENT | VERTEX | GEOMETRY.

MFString [] <emphasis role="bold">url</emphasis> []
  # The source code, like ShaderPart.url.
  # May come from an external file (url),
  # or inline (following "data:text/plain,").
  # In XML encoding, may also be inlined in CDATA.
</screen>

<para>Inside the effect part source code, the functions that enhance
standard shaders behavior are recognized by names starting with <literal>PLUG_</literal>.
Of course other functions can also be defined and used.
Uniform variables can be passed to the effect,
also varying variables can be passed between the vertex and fragment
parts, just like with standard shader nodes.
</para>

<para>
In a single <literal>EffectPart</literal> node, many <literal>PLUG_</literal>
functions may be declared. However, all plug functions must be declared in the appropriate
effect type. For example, the <literal>texture_apply</literal> plug cannot be used
within a <literal>VERTEX</literal> shader.
If the effect requires some processing per-vertex and some per-fragment,
it is necessary to use two <literal>EffectPart</literal> nodes, with different types.
This allows to implement our system for
<!--
While this may seem like an arbitrary limitation,
this reflects how shader parts are declared in
-->
shading languages with
separate namespaces for vertex and fragment parts (like GLSL).
A single part may declare many variables and functions,
but it must be completely contained within a given shader type.
</para>

<para>Note that it is completely reasonable to have an <literal>EffectPart</literal> node
with source code that does not define any <literal>PLUG_xxx</literal> functions.
Such <literal>EffectPart</literal> node may be useful for defining shading language
utility functions, used by other effect parts.
</para>

<para>For shading languages that have separate compilation units
(like the <emphasis>OpenGL Shading Language</emphasis>) the implementation may choose to place
each effect part in such separate unit. This forces the shader code to be
cleaner, as you cannot use undeclared functions and variables from other parts.
It also allows for cleaner error detection (parsing errors will be detected
inside the given unit).
</para>

<!--
<para>
We have also considered and rejected a different approach to use plugs.
In that approach, the plug name was indicated by a new field of
the <literal>EffectPart</literal> node, not by a special <literal>PLUG_</literal> function name
inside the shader code.
However, the implementation may need to know the full declaration
of a plug function, to make a forward or external declaration of it.
One way to overcome this problem was to require repeating this declaration
in another field. Another solution was to split shader code into more
parts (for example, one part declares the uniform variables, one part declares
the plug function, one part defines the function body and so on).
Both approaches seemed uncomfortable for authors
and they didn't really offer a simpler implementation, so we dropped this idea.
The current approach, to find the declarations of <literal>PLUG_xxx</literal> functions
inside a complete shader code, is easy to implement and results in clean
shader code of the effects. It also allows us to naturally use
the separate compilation units in case of GLSL.</para>

<para>
Detecting special <literal>PLUG_</literal> function names inside the shader code
is trivial, and it turned out to be the best approach to design our effects.
This means that each effect code is clean, and can be compiled separately
from others. It allows us to naturally use
the <emphasis>separate compilation units</emphasis> in case of GLSL implementation.</para>
-->

</section>

<section id="section.effects_on_shape">
<title>Effects for particular shapes</title>

<para>There are various places where an <literal>Effect</literal> node may be used.
To apply an effect for a given shape appearance, it can be placed
on the new <literal>Appearance.effects</literal> list:</para>

<screen><phrase role="underline">Appearance</phrase>

MFNode [] <emphasis role="bold">effects</emphasis> [] # Effect
</screen>

<para>All the effects on this list (with suitable language) will be used.
<!--
Note that this is different
than the <literal>Appearance.shaders</literal>, which chooses only one shader.
For effects, we choose all of them.
-->
This allows authors to define a library of independent shader effects
and then trivially pick desired effects for each particular shape.
Simply placing two effects on the <literal>Appearance.effects</literal> list
makes them cooperate correctly.
<!--
. This also allows to
define a library of effects, that can be composited without any work
needed by user.
--></para>

<figure id="figure.toon_and_fresnel">
  <title>Toon and Fresnel effects combined.</title>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/fresnel_and_toon.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/fresnel_and_toon.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
</figure>

<para>Note that all introduced nodes benefit from X3D mechanism to reuse the nodes
by reference (the <literal>DEF</literal> / <literal>USE</literal> keywords). Reusing the
<literal>Effect</literal> nodes
is most natural and allows to combine existing effects in any desired way.
Reusing the <literal>EffectPart</literal> nodes is also useful, when some effects
would like to share a particular piece of code. For example,
the same <literal>EffectPart</literal> node, with a library of useful
shading language functions, may be used for many effects.</para>

</section>

<section id="section.effects_on_group">
<title>Effects for a group of nodes</title>

<para>The <literal>Effect</literal> node is a descendant of the abstract <literal>X3DChildNode</literal>.
As such it can be placed directly within X3D grouping nodes like
<literal>Group</literal>, <literal>Transform</literal> and at the top level of the X3D file.
Such effect will apply to all the shapes within the given group.
The scope rules follow the X3D conventions for other nodes,
like pointing device sensor nodes and <literal>LocalFog</literal>.</para>

<para>The <literal>LocalFog</literal> example is worth emphasizing. Using our system,
an X3D viewer can implement the <literal>LocalFog</literal> node as a prototype
that expands to our <literal>Effect</literal> node. This results in a 100% correct
and easy implementation of the standard <literal>LocalFog</literal> node.</para>

<para>As one of the demos, we have implemented a realistic
animated volumetric fog, where the fog density is stored in
a 3D smooth noise texture (idea from <xref linkend="bib.humus.volumetricfog" />).
In a fragment shader, the 3D&nbsp;texture is sampled
along the line between the camera and pixel position in the 3D&nbsp;space. This makes a very
convincing effect of a dense fog. The <literal>Effect</literal> node with
appropriate shader code is placed at the top level of the X3D file,
so it simply works for all shapes. See <xref linkend="figure.fog" />.</para>

<para role="figure_2_column">
<figure id="figure.fog">
  <title>Volumetric fog with animated density.</title>

<informaltable frame="none">
  <tgroup cols="2" align="center">
  <colspec colnum='1' colname='col1' colwidth='1*'/>
  <colspec colnum='2' colname='col2' colwidth='1*'/>

  <tbody>
    <row><entry>
      <mediaobject>
      <imageobject role="html"> <imagedata format="PNG" fileref="images/volumetric_animated_fog_no_fog.png" /> </imageobject>
      <imageobject role="fo">   <imagedata format="PNG" fileref="images/volumetric_animated_fog_no_fog.png" width="2.7in" contentwidth="2.7in" /> </imageobject>
      </mediaobject>
      No fog.
    </entry>
    <entry>
      <mediaobject>
      <imageobject role="html"> <imagedata format="PNG" fileref="images/volumetric_animated_fog_no_light.png" /> </imageobject>
      <imageobject role="fo">   <imagedata format="PNG" fileref="images/volumetric_animated_fog_no_light.png" width="2.7in" contentwidth="2.7in" /> </imageobject>
      </mediaobject>
      No lighting.
      Note that the fog is assumed to have its own ambient lighting,
      so it colors the image even in this case.
    </entry></row>
    <row><entry>
      <mediaobject>
      <imageobject role="html"> <imagedata format="PNG" fileref="images/volumetric_animated_fog_all.png" /> </imageobject>
      <imageobject role="fo">   <imagedata format="PNG" fileref="images/volumetric_animated_fog_all.png" width="2.7in" contentwidth="2.7in" /> </imageobject>
      </mediaobject>
      Lights and fog.
    </entry>
    <entry /></row>
  </tbody>
  </tgroup>
</informaltable>
</figure>
</para>

</section>

<section id="section.effects_on_lights">
<title>Light sources effects</title>

<para>The nice feature of our system is that effects can be attached to various
types of objects, not just shapes. For example a particular light source
may have a shader effect assigned.
This allows to modify the contribution of a given light.
For example the spot light shape can be modified, possibly
based on some texture information (see <xref linkend="figure.fancy_spot" />).
Or a different lighting model may be implemented, like anisotropic Ward
or Cook-Torrance.
<!--
<para>,
or even replace the default
calculation of the light source contribution. In the second case,
the default calculation will not even be used in the shader,
so it will not slow down the calculation without a reason.</para>
Removed: replacing not really implemented now, not needed.
-->
To make this possible, the <literal>effects</literal> field is added to every light node:</para>

<screen><phrase role="underline">X3DLightNode</phrase>

MFNode [] <emphasis role="bold">effects</emphasis> [] # Effect
</screen>

<figure id="figure.fancy_spot">
  <title>Textured spot light with shadow.</title>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/fancy_light_spot_shape.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/fancy_light_spot_shape.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
</figure>

</section>

<section id="section.effects_on_texture">
<title>Texture effects</title>

<para>Just like the light sources, also each texture node may define its own effects:
</para>

<screen><phrase role="underline">X3DTextureNode</phrase>

MFNode [] <emphasis role="bold">effects</emphasis> [] # Effect
</screen>

<para><literal>X3DTextureNode</literal> is an ancestor for all the standard texture nodes,
like the <literal>ImageTexture</literal>. This allows to modify any X3D texture
by shader effects.
A plug <literal>texture_color</literal> may be used to change the texture color,
taking into account the current texture coordinates and other information.</para>

<section id="section.procedural_textures">
<title>Procedural textures</title>

<para>A new X3D node <literal>ShaderTexture</literal> is available for creating
procedural textures using the GPU shading languages.
<!--
This is suitable
if the texture is defined completely using the shading language.
-->
The texture contents are not stored anywhere (not even on GPU)
and the renderer does not manage any texture resources.
From a GPU point of view, there is no texture.
<!-- <footnote>But the spoon is real, we swear.</footnote> -->
There is only a shader function that generates colors
based on some vectors. By wrapping such function inside
the <literal>ShaderTexture</literal> node, it can be treated exactly like other textures
in the scene. In particular, texture coordinates
(explicit or generated) can be comfortably provided
for the procedural texture.
Effectively, it behaves like a normal texture node, with all the related
X3D features.</para>

<para>The new texture node specification:</para>

<screen><phrase role="underline">ShaderTexture : X3DTextureNode</phrase>

MFNode [] <emphasis role="bold">effects</emphasis> [] # Effect

SFString [] <emphasis role="bold">defaultTexCoord</emphasis> "BOUNDS2D"
  # ["BOUNDS2D"|"BOUNDS3D"]
</screen>

<para>Actually, the <literal>effects</literal> field is already defined in
the base <literal>X3DTextureNode</literal> class mentioned previously.
It is repeated here only for completeness.</para>

<para>An effect overriding the <literal>texture_color</literal> plug
should be included, otherwise texture colors are undefined.
Our implementation
sets the default texture color to pink (RGB(1,&nbsp;0,&nbsp;1)), so it stands out,
reminding author to override it.</para>

<para>The texture coordinates, or the algorithm to generate them,
can be explicitly specified, just like for any other texture in X3D.
This is done by placing any <literal>X3DTextureCoordinateNode</literal>
node inside the geometry <literal>texCoord</literal> field.
Both explicit texture coordinate lists (<literal>TextureCoordinate</literal>
<literal>TextureCoordinate3D</literal>, <literal>TextureCoordinate4D</literal>)
as well as the coordinate generator nodes
(like <literal>TextureCoordinateGenerator</literal> and
<literal>ProjectedTextureCoordinate</literal>) are allowed.
Note that projective texture mapping
by the <literal>ProjectedTextureCoordinate</literal>
is also our X3D extension, see <xref linkend="bib.castleengine.projectivetexturing" />.</para>

<para>When the texture coordinates are not given,
the <literal>defaultTexCoord</literal> field determines how they are generated:</para>

<orderedlist>
  <listitem><para><literal>"BOUNDS2D"</literal> generates 2D texture coordinates,
    adapting to the two largest bounding box sizes. The precise behavior
    of <literal>"BOUNDS2D"</literal> follows the X3D <literal>IndexedFaceSet</literal> specification.</para>

    <para>This is most comfortable
    when the texture color depends only on the XY components of the texture coordinate.
    The 3rd texture coordinate component is always 0,
    and the 4th component is always 1.</para></listitem>

  <listitem><para><literal>"BOUNDS3D"</literal> generates 3D texture coordinates.
    The texture coordinates are adapted to all three bounding box sizes,
    precisely following X3D specification section
    <emphasis>"Texture coordinate generation for primitive objects"</emphasis>
    of the <emphasis>Texturing3D</emphasis> component.</para>

    <para>This is most suitable for true 3D textures. The 4th texture coordinate
    component can be ignored. Or the 4D vector may be treated as homogeneous,
    as <literal>"BOUNDS3D"</literal> will always
    set the 4th component to 1.</para></listitem>
</orderedlist>

<para>The <literal>"BOUNDS*"</literal> names are consistent
with another of our engine extensions. Namely, we allow
the values <literal>"BOUNDS2D"</literal> and <literal>"BOUNDS3D"</literal>
to be also used for the <literal>TextureCoordinateGenerator.mode</literal> field.
See <xref linkend="bib.castleengine.texcoordbounds" />.</para>

<para>In the end, the idea is that using a <literal>ShaderTexture</literal>
should be as comfortable as any other texture node.</para>

</section>

<section id="section.when_use_shader_texture">
<title>When to use the ShaderTexture</title>

<para>For textures other than the <literal>ShaderTexture</literal>,
when the <literal>texture_color</literal> plugs are called,
the internal shaders have already calculated the initial texture
color by actually sampling the texture image. This is useful if you
want to modify this color. If you'd rather ignore the normal
sampled color, and always override it with your own, consider using
the special <literal>ShaderTexture</literal> node instead. Using
a normal texture node (like <literal>ImageTexture</literal>) for this
would be uncomfortable, as you would have to load a dummy texture image,
and the shaders could (depending on optimization) waste some time
on calculating a color that will be actually ignored later.</para>

<para>Note that in all cases (effects at <literal>ImageTexture</literal>,
at <literal>ShaderTexture</literal>, etc.) you can always use additional
textures inside the effect. Just like inside a standard <literal>ComposedShader</literal>,
you can declare an <literal>SFNode</literal> field inside an <literal>Effect</literal>
to pass any texture node to the shader as a uniform value.
This allows to combine any number of textures inside an effect.
The only difference
between <literal>ShaderTexture</literal> and other textures is what the system
does automatically for you, that is what color is passed
to the first <literal>texture_color</literal> plug.</para>

<figure id="figure.shader_texture_edge_detection">
  <title>ShaderTexture doing an edge detection operation on a normal ImageTexture.</title>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/shader_texture_edge_detection.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/shader_texture_edge_detection.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
</figure>

</section>

<section id="section.filtering">
<title>Independence from texture filtering</title>

<para>Note that the shader effects for textures are calculated at each screen fragment
(not at each texel). So the effects are not concerned about the texture size
or texture filtering options. We can just use the interpolated texture
coordinates in the <literal>texture_color</literal> plug.
<xref linkend="figure.shader_texture_no_filtering_problems" />
shows a yellow arc drawn on a texture by our effect.
As you can see, the arc is drawn perfectly, without any concern about
the pixel resolution of the underlying texture.
</para>

<figure id="figure.shader_texture_no_filtering_problems">
  <title>Texture effects are not concerned with small texture resolution.</title>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/shader_texture_no_filtering_problems.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/shader_texture_no_filtering_problems.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
</figure>

</section>

</section>

</chapter>

<chapter id="chapter.custom_plugs">
<title>Defining custom plugs</title>

<para>In a shader code, new plug may be defined by a magic comment:</para>

<screen>/* PLUG: name (param1, param2, ...) */
</screen>

<para>This defines a point where calls to user functions declared as
<literal>PLUG_name</literal> will be inserted. They will be called with given
parameters.</para>

<para>Many effects may use the same <literal>PLUG_name</literal>.
Even within a single effect, the same <literal>PLUG_name</literal> may be used
many times. All the <literal>PLUG_name</literal> functions
will be uniquely renamed to not collide with each other.</para>

<para>The calls will be added in the order they are specified on the
<literal>effects</literal> list. More precisely, the most local effects
(at light sources and textures) are called first, then the effects
at shape appearance, and finally the effects inside the grouping nodes.
Although, preferably, for most effects this order will not matter.</para>

<para>A plug is often defined to allow modifying some parameter
repeatedly (like adding or modulating the fragment color),
so one or more of the parameters are often allowed to be handled
as <literal>inout</literal> values.</para>

<para>The same plug name may be defined many times in the source shader.
This means that a single <literal>PLUG_xxx</literal> function will be called
many times. For example, this is useful when the algorithm is naturally
expressed as a loop, but it had to be unrolled for shader source
(for example, to slightly tweak some loop iterations).
The plug names that are available per-light source and per-texture
are an example of this.
<!--
If you use the <literal>PLUG_texture_color</literal>
inside <literal>Appearance.effects</literal>, you change the color of all
the textures (even shader textures).
Removed: Not really available, as params to texture_color differ.
-->
Using the <literal>PLUG_light_scale</literal>
inside <literal>Appearance.effects</literal>, the intensity
of all the light sources on the given shape can be changed. Contrast this with using
the same <literal>PLUG_light_scale</literal> inside a <literal>X3DLightNode.effects</literal>,
where only the given light node contribution is changed.</para>

<para>Currently all the plugs must be procedures, that is their result type
must be declared as <literal>void</literal>. We have been considering
a possibility of functions, where part of the calculation may be replaced
by a call to a plugged function. While not difficult to implement,
this idea seems unnecessary after many tests.
Procedural plugs are easier to declare, as the call to the plug
may be simply inserted, while in case of function it will have to replace
some previous code. This also means that using a procedural plug
<emphasis>never</emphasis> replaces or removes some existing code, which is a very nice
concept to keep. We want the effects to cooperate with each other,
not to <quote>hijack</quote> from each other some parts of the functionality.</para>

<para>New plugs can be defined inside the <literal>Effect</literal> nodes,
as well as inside the complete shaders (like standard
<literal>ComposedShader</literal> nodes).
In the first case, the plugs
are only available for the following effects of the same shape.</para>

<para>The advantage of using magic comments to define plugs is that
they can be ignored and a shader source remains valid.
This means that <literal>ComposedShader</literal> nodes can define custom plugs
and still work (although with no extra effects) even in X3D browsers
that do not support our extensions.</para>

<section id="section.forward_declarations">
<title>Forward declarations</title>

<para>Suppose we have an effect&nbsp;<emphasis>X</emphasis> that defines a new plug,
by including a magic <literal>/* PLUG: ... */</literal> comment.
When this plug is used by another effect&nbsp;<emphasis>Y</emphasis>,
then an appropriate function call is automatically inserted into the generated shader.
In the middle of the source code of effect&nbsp;<emphasis>X</emphasis>,
a function defined in effect&nbsp;<emphasis>Y</emphasis> has to be called. This is the simplest
implementation of our plugs.</para>

<para>Additionally, a forward or external declaration of the called function
may need to be inserted into the effect&nbsp;<emphasis>X</emphasis>. That is because&nbsp;<emphasis>Y</emphasis>
may be in a separate compilation unit (in case of GLSL),
or just defined lower in the code. In simple cases, such forward or external
declarations can be inserted right at the beginning of effect&nbsp;<emphasis>X</emphasis> code.
</para>

<para>Some shading language directives are required to be placed before
all normal declarations. For example, in case of the <emphasis>OpenGL shading language</emphasis>,
the <literal>#version</literal> as well as some <literal>#extension</literal> directives
must occur at the beginning of the shader code.
To handle such cases, another magic comment <literal>/* PLUG-DECLARATIONS */</literal>
is available.
If present, it signifies a place where forward or external declarations
should be inserted.</para>

<!--
These (forward or external) declarations are inserted at
the point of special <literal>/* PLUG-DECLARATIONS */</literal>
comment, or (when it is missing) simply at the beginning of shader source.
This applies in the same way to shader code inside an <literal>EffectPart</literal>,
or inside standard X3D node like <literal>ShaderPart</literal>.

<literal>/* PLUG-DECLARATIONS */</literal> should be placed after such directives
and before any <literal>/* PLUG: ... */</literal> declarations.
-->

</section>

<section id="section.invalid_shader_code">
<title>Invalid shader code</title>

<para>The behavior is defined only if the provided shading language code
is a correct, self-contained code. The errors (like unterminated block)
<!-- or an unterminated comment) -->
may only be detected after the complete shader
is determined and compiled by the GPU.
It should be noted that for shading languages with separate compilation units,
the parsing errors can be at least reported always for the correct code piece
(effect part).</para>

<para>An invalid effect code may disable
all other user effects on the given shape. That is because
there's no reliable way to detect which user effect prevents the compilation.
At least for shading languages
without the <emphasis>separate compilation units</emphasis> feature.
In such case, the application may decide to disable <emphasis>all</emphasis>
user-provided effects for given shape.
However, this isn't exactly a new problem &mdash; bad shader code
may always cause enough trouble to prevent the shape from being sensibly rendered.</para>

<!--
<para>It also isn't a security problem &mdash;
X3D <literal>ComposedShader</literal> node allows users
to execute any shading language code anyway. So if there's anything dangerous
(for example a buggy OpenGL may cause the browser process to exit with
segmentation fault on some special shader code snippets),
it could be done without using our effects as well.
This is the same security challenge as the new WebGL is facing &mdash;
some bugs in 3D libraries (like OpenGL) become security problems when
the file author has flexibility to (almost directly) issue OpenGL
calls or provide custom shader code.</para>
-->

<!--
<para>In all our practical tests, this approach didn't cause any problems.
Since each effect can be implemented separately, it can also be tested separately,
and in practice it's usually obvious where to look for the parsing error.</para>
-->

<!--
<para>It may be noted that in nasty cases,
a deliberately poorly coded effect may cause troubles for other effects.
In particular, since you can use <literal>#define</literal> and macros in your effect code,
you can do nasty tricks to break other effects. You can make them compile,
but function incorrectly. However, we do not consider
it a real problem. You really have to deliberately want to do something bad,
and be familiar with internals about how the shader is generated,
to achieve some particular weird behavior.
It does not happen by accident in our experience.
Moreover, you may need to use the internal knowledge
how the other effects are implemented (maybe how they are implemented
inside the browser).</para>
-->

<para>The <emphasis role="bold">application does not need to parse the shader code</emphasis> at any point.
Only a trivial text search in the code is necessary to detect the magic
plug function names and comments.
<!-- Still, an incorrect effect code may cause the whole shader to malfunction. -->
</para>

</section>
</chapter>

<chapter id="chapter.examples">
<title>Examples</title>

<para>Effects may define and use their own uniform variables, including textures,
just like the standard shader nodes. So we can combine any number of textures
inside an effect. As an example we wrote a simple effect that mixes a couple of
textures based on a terrain height (see <xref linkend="figure.terrain" />).
We could also pass any other uniform value to the effect, for example
passing the current time from an X3D <literal>TimeSensor</literal> allows to make
animated effects.</para>

<figure id="figure.terrain">
  <title>ElevationGrid with 3 textures mixed (based on the point height) inside the shader.</title>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/terrain.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/terrain.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
</figure>

<para>We can wrap 2D or 3D noise inside a <literal>ShaderTexture</literal>
(see <xref linkend="figure.noise" />).
A texture node like <literal>NoiseTexture</literal> from InstantReality
<xref linkend="bib.instantreality.noisetex" />
may be implemented on GPU by a simple prototype using the <literal>ShaderTexture</literal>.
</para>

<figure id="figure.noise">
  <title>3D and 2D smooth noise on GPU, wrapped in a ShaderTexture.</title>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/noise.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/noise.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
</figure>

<para><emphasis>Water</emphasis> is very nice to implement with the help of our effects,
as a proper water simulation
is naturally a combination of a couple effects.
To simulate waves we want to vary vertex
heights, or vary per-fragment normal vectors (for best results,
we want to do both things).
We also want to simulate the fact that water has reflections and
is transparent. We have implemented a nice water using this approach,
with (initially) two independent effect nodes. See <xref linkend="figure.water" />.</para>

<para>We were also able to easily test
two alternative approaches for generating water normal vectors.
One approach was to take normals from the pre-recorded sequence of images
(encoded inside X3D <literal>MovieTexture</literal>,
with noise images generated by the <emphasis>Blender</emphasis> renderer).
The second approach was to calculate normals on the GPU from
a generated smooth 3D noise.
The implementation of these two approaches is contained in two separate
<literal>Effect</literal> nodes, and is concerned
only with calculating the normal vectors in the object space.
Yet another <literal>Effect</literal> node is responsible for
transforming these normal vectors into the eye space.
This way we have extracted all the common logic into a separate effect,
making it clear where the alternative versions differ and what they have
in common.
This was possible because one effect can define
new plug names, that can be used by the other effects.</para>

<para>As for the question <quote>Which approach to generating water normals
turned out to be better?</quote>
Predictably, we showed that using GPU noise is slower, requires a better GPU,
but also improves the quality noticeably. With GPU noise, there is no problem
with aliasing of the noise texture and the noise parameters can be adjusted
in real-time.</para>

<para role="figure_2_column">
<figure id="figure.water">
  <title>Water using our effects framework.</title>

<informaltable frame="none">
  <tgroup cols="2" align="center">
  <colspec colnum='1' colname='col1' colwidth='1*'/>
  <colspec colnum='2' colname='col2' colwidth='1*'/>

  <tbody>
    <row><entry>
      <mediaobject>
      <imageobject role="html"> <imagedata format="PNG" fileref="images/water_shaders_0.png" /> </imageobject>
      <imageobject role="fo">   <imagedata format="PNG" fileref="images/water_shaders_0.png" width="2.7in" contentwidth="2.7in" /> </imageobject>
      </mediaobject>
      Per-pixel lighting.
    </entry>
    <entry>
      <mediaobject>
      <imageobject role="html"> <imagedata format="PNG" fileref="images/water_shaders_1.png" /> </imageobject>
      <imageobject role="fo">   <imagedata format="PNG" fileref="images/water_shaders_1.png" width="2.7in" contentwidth="2.7in" /> </imageobject>
      </mediaobject>
      Bump mapping. <!-- (with per-pix lighting) -->
    </entry></row>
    <row><entry>
      <mediaobject>
      <imageobject role="html"> <imagedata format="PNG" fileref="images/water_shaders_2.png" /> </imageobject>
      <imageobject role="fo">   <imagedata format="PNG" fileref="images/water_shaders_2.png" width="2.7in" contentwidth="2.7in" /> </imageobject>
      </mediaobject>
      Reflections and refractions. <!-- (with per-pix lighting) --> <!-- (by a single environment cube map texture).-->
    </entry>
    <entry>
      <mediaobject>
      <imageobject role="html"> <imagedata format="PNG" fileref="images/water_shaders_3.png" /> </imageobject>
      <imageobject role="fo">   <imagedata format="PNG" fileref="images/water_shaders_3.png" width="2.7in" contentwidth="2.7in" /> </imageobject>
      </mediaobject>
      All effects.
    </entry></row>
  </tbody>
  </tgroup>
</informaltable>
</figure>
</para>

<para>
We also have plugs to change the geometry in object space.
Again, since the effect is integrated with all the browser shaders,
you only need to code a simple function to change the vertex positions
as you want. The effect instantly works with all the lighting and texturing
conditions.
Since the transformation is done on GPU, there's practically
no speed penalty for animating thousands of flowers in our test scene.
See <xref linkend="figure.flowers" />.
</para>

<figure id="figure.flowers">
  <title>Flowers bending under the wind, transformed on GPU in object space.</title>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/flowers.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/flowers.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
</figure>

<para>We would like to emphasize that all the effects demonstrated here
are theoretically already possible to implement using the standard
X3D <emphasis>Programmable shaders component</emphasis> <xref linkend="bib.x3d_shaders" />.
However, such implementation
would be extremely cumbersome.
You would first have to implement all the necessary multi-texturing, lighting,
shadows, and other rendering features in a shader code.
This is a large work if we consider all the X3D rendering options.
Also note that a shader should remain optimized for a particular setting.
<!--
Actually, it isn't even possible, unless we can calculate some global options,
like which light sources and fog nodes affect the given shape.
-->
The only manageable way to do this, that would work for all the lighting
and texturing conditions, is to write a shader generator program.
Which is actually exactly what our effects already do for you &mdash;
the implementation of our effects constructs and links
the appropriate shader code, gathering the information from all the nodes
that affect the given shape. The information is nicely integrated
with X3D nodes, effects are specified at suitable nodes, and their
uniform values and attributes are integrated with X3D fields.</para>

<para>Many complete example models using our effects
are referenced from our page on
<ulink url="http://castle-engine.sourceforge.net/compositing_shaders.php" />.
You can open these examples using any of our engine tools,
like <literal>view3dscene</literal>
(<ulink url="http://castle-engine.sourceforge.net/view3dscene.php" />).</para>

<para>You can run <literal>view3dscene</literal> with <literal>--debug-log-shaders</literal> command-line
option. Output will show you the final shader code generated,
and also the OpenGL log after linking the shaders.
Be sure to redirect the output to a file as it may be quite large.
<!-- and you may want to test it first
with a simple scene with one shape &mdash; -->
This is a useful way to learn about our shader rendering internals.</para>

<para>Another useful option to try in <literal>view3dscene</literal> is to switch to
<emphasis>View
<phrase role="symbol">&rarr;</phrase> Shaders
<phrase role="symbol">&rarr;</phrase> Enable For Everything</emphasis> mode.
This will force shader rendering for all the shapes,
while by default we use shader rendering only for the shapes that
require particular effects (shaders by <literal>ComposedShader</literal>, effects
described in this paper, shadow maps and such).
Forcing shader rendering for everything allows to see
how our shaders implement the whole X3D lighting and texturing model.
It also forces all the lighting calculation to be done per-pixel, resulting
in perfect specular highlights and spot light shapes.</para>

</chapter>

<chapter id="chapter.implementation">
<title>Implementation notes</title>

<para>We have implemented all the X3D extensions described in this paper
for the <emphasis>OpenGL Shading Language</emphasis> (GLSL).
However, we have designed our extensions
to be applicable to other shading languages as well (like Cg or HLSL)
and we believe they can be handled in a similar fashion.
In particular, we have tested that the <emphasis>separate compilation units</emphasis>
concept of GLSL, while very useful, is not necessary for proper implementation
of our effects.
</para>

<!-- TODO: review, maybe uncomment:
concept, that is specific to GLSL, is useful here:
it forces
cleaner shader code (you cannot use undeclared functions from other
shader parts) and it gives you better line numbers in error messages
(although a pre-processor directive like <literal>#line</literal> could also be used for
this).

and we think that the same set of plugs will be useful for them &mdash; but it's just a theory.
An implementation of our effects for other shading languages may
find other opportunities for plugs.
In particular, we have tested that the <emphasis>separate compilation units</emphasis>
of GLSL are not necessary for a correct implementation of our effects.
We also believe that most of our plugs (like <quote>do something in object space</quote>,
<quote>do something in eye space</quote>) are generic enough to be usable
with all shading languages.
-->

<para>
Our approach does not cause any speed loss. Effects code is just
combined into the final shader code, without any transformations that
could make it slower. Our process of <quote>combining</quote> effects is essentially
adding function calls around. Fortunately, a function call has no speed
penalty. Existing shading languages are defined
such that functions can always be inlined (there is no recursion allowed,
and parameter qualifiers have simple interpretation),
and as far as we know they are actually always inlined by existing
shading language compilers.</para>

</chapter>

<chapter id="chapter.conclusion">
<title>Conclusion</title>

<para>We show a new approach for developing effects using the GPU shading languages.
It allows to combine various shader effects with each other
and with application internal shaders.
Our approach is relatively easy
to implement and allows the authors to directly use the existing GPU shading
languages.
We propose a number of extensions to the X3D,
an open standard for 3D data, to make our effects available for 3D
content authors. We have implemented our approach for the GLSL shading language.
</para>

</chapter>

<chapter id="acknowledgements">
<title>Acknowledgements</title>

<para>
A lot of people helped and encouraged the development of our VRML/X3D engine,
with it's rendering features and extensions. A big <quote>thank you</quote>
goes to all of you!
</para>

</chapter>

<bibliography id="bibliography">
<title>References</title>

<bibliomixed id="bib.x3d">
  <abbrev>X3D</abbrev>
  <author><othername>Web3D Consortium</othername></author>.
  <title><emphasis>Extensible 3D (X3D) Graphics Standard</emphasis></title>.
  <pubdate>2008</pubdate>.
  <bibliomisc>ISO/IEC 19775-1.2:2008. See <ulink url="http://web3d.org/x3d/specifications/" />.</bibliomisc>
</bibliomixed>

<bibliomixed id="bib.x3d_shaders">
  <abbrev>X3D Shaders</abbrev>
  <bibliomset relation='article'>
    <abbrev>X3D Shaders</abbrev>
    GonÃ§alo Nuno Moutinho de Carvalho, Tony Gill and Tony Parisi.
    <title role='article'>X3D programmable shaders</title>.
  </bibliomset>
  <bibliomset relation='journal'>
    <title>Proceedings of the ninth international conference on 3D Web technology</title>.
    <publishername>ACM</publishername>, <pubdate>2004</pubdate>.
  </bibliomset>
  <bibliomisc>Available online as part of the X3D specification, see <ulink url="http://web3d.org/x3d/specifications/ISO-IEC-19775-1.2-X3D-AbstractSpecification/Part01/components/shaders.html" /></bibliomisc>
</bibliomixed>

<bibliomixed id="bib.glsl">
  <abbrev>GLSL</abbrev>
  Khronos Group.
  <title><emphasis>OpenGL Shading Language</emphasis></title>.
  <bibliomisc>See <ulink url="http://www.opengl.org/documentation/glsl/" />.</bibliomisc>
</bibliomixed>

<bibliomixed id="bib.glsl_book">
  <abbrev>GLSL Book</abbrev>
  Randi J. Rost.
  <title><emphasis>OpenGL Shading Language</emphasis></title>.
  <publishername>Addison-Wesley</publishername>, <pubdate>2004</pubdate>.
</bibliomixed>

<bibliomixed id="bib.cg">
  <abbrev>Cg</abbrev>
  <title><emphasis>Cg - The Language for High-Performance Realtime Graphics</emphasis></title>.
  NVidia.
  <bibliomisc>See <ulink url="http://developer.nvidia.com/page/cg_main.html" />.</bibliomisc>
</bibliomixed>

<bibliomixed id="bib.hlsl">
  <abbrev>HLSL</abbrev>
  Microsoft.
  <title><emphasis>HLSL</emphasis></title>.
  <bibliomisc>See <ulink url="http://msdn.microsoft.com/en-us/library/bb509561\%28v=vs.85\%29.aspx" />.</bibliomisc>
</bibliomixed>

<bibliomixed id="bib.sh">
  <abbrev>Sh</abbrev>
  Stefanus Du Toit and Michael McCool.
  <title><emphasis>Metaprogramming GPUs with Sh</emphasis></title>.
  <publishername>A K Peters/CRC Press</publishername>, <pubdate>2004</pubdate>.
  <!-- Links to "Metaprogramming GPUs with Sh":
   http://www.amazon.com/Metaprogramming-GPUs-Sh-Stefanus-Toit/dp/1568812299
   http://books.google.com/books?id=8RX4RmFRLmgC&pg=PA79&lpg=PA79&dq=ShAttrib2f&source=bl&ots=IOxd1-BQLL&sig=AIPgFRmbodNpCLWmwk-QV5JUjVo&hl=pl&ei=EylRTe7RB8qeOsiQ1aQI&sa=X&oi=book_result&ct=result&resnum=7&ved=0CEkQ6AEwBg#v=onepage&q=ShAttrib2f&f=false
  -->
</bibliomixed>

<bibliomixed id="bib.ogre_shader">
  <abbrev>OGRE Shader</abbrev>
  <title><emphasis>OGRE Wiki - RT Shader System</emphasis></title>.
  <bibliomisc>See <ulink url="http://www.ogre3d.org/tikiwiki/RT+Shader+System&amp;structure=Development" />.</bibliomisc>
</bibliomixed>

<bibliomixed id="bib.anysl">
  <abbrev>AnySL</abbrev>
  <bibliomset relation='article'>
    Ralf Karrenberg, Dmitri Rubinstein, Philipp Slusallek and Sebastian Hack.
    <title role='article'>AnySL: efficient and portable shading for ray tracing</title>.
  </bibliomset>
  <bibliomset relation='journal'>
    <title>Proceedings of the Conference on High Performance Graphics</title>.
    <publishername>Eurographics Association</publishername>, <pubdate>2010</pubdate>.
  </bibliomset>
  <bibliomisc>See <ulink url="http://portal.acm.org/citation.cfm?id=1921479.1921495" />. See also AnySL website <ulink url="http://www.cdl.uni-saarland.de/projects/anysl/" />.</bibliomisc>
</bibliomixed>

<bibliomixed id="bib.spark">
  <abbrev>Spark</abbrev>
  <bibliomset relation='article'>
    Tim Foley and Pat Hanrahan.
    <title role='article'>Spark: Modular, Composable Shaders for Graphics Hardware</title>.
  </bibliomset>
  <bibliomset relation='journal'>
    <title>Proceedings of SIGGRAPH 2011</title>.
    <publishername>ACM</publishername>, <pubdate>2011</pubdate>.
  </bibliomset>
  <bibliomisc>See <ulink url="http://graphics.stanford.edu/papers/spark/" />.</bibliomisc>
</bibliomixed>

<bibliomixed id="bib.web3d2010.declarativeshader">
  <abbrev>X3D DeclarativeShader</abbrev>
  <bibliomset relation='article'>
    Karsten Schwenk, Yvonne Jung, Johannes Behr and Dieter W. Fellner.
    <title role='article'>A modern declarative surface shader for X3D</title>.
  </bibliomset>
  <bibliomset relation='journal'>
    <title>Proceedings of the 15th International Conference on Web 3D Technology</title>.
    <publishername>ACM</publishername>, <pubdate>2010</pubdate>.
  </bibliomset>
  <bibliomisc>See <ulink url="http://doi.acm.org/10.1145/1836049.1836051" />.</bibliomisc>
</bibliomixed>

<bibliomixed id="bib.humus.volumetricfog">
  <abbrev>Volumetric Fog</abbrev>
  <firstname>Emil</firstname> <surname>Persson</surname> "Humus".
  <title><emphasis>Volumetric Fogging 2</emphasis></title>.
  <pubdate>2006</pubdate>.
  <bibliomisc>See <ulink url="http://www.humus.name/index.php?page=3D&amp;ID=70" />. Nice overview also on <ulink url="http://www.evl.uic.edu/sjames/cs525/shader.html" />.</bibliomisc>
</bibliomixed>

<bibliomixed id="bib.castleengine.shadowmaps">
  <abbrev>X3D Shadow Maps</abbrev>
  <bibliomset relation='article'>
    <firstname>Michalis</firstname> <surname>Kamburelis</surname>.
    <title role='article'>Shadow maps and projective texturing in X3D</title>.
  </bibliomset>
  <bibliomset relation='journal'>
    <title>Proceedings of the 15th International Conference on Web 3D Technology</title>.
    <publishername>ACM</publishername>, <pubdate>2010</pubdate>.
  </bibliomset>
  <bibliomisc>See <ulink url="http://castle-engine.sourceforge.net/x3d_extensions_shadow_maps.php" />.</bibliomisc>
</bibliomixed>

<bibliomixed id="bib.castleengine.bumpmapping">
  <abbrev>X3D Bump Mapping</abbrev>
  <firstname>Michalis</firstname> <surname>Kamburelis</surname>.
  <title><emphasis>Bump mapping extensions</emphasis></title>.
  <pubdate>2008</pubdate>.
  <bibliomisc>See <ulink url="http://castle-engine.sourceforge.net/x3d_extensions.php#section_ext_bump_mapping" /></bibliomisc>
</bibliomixed>

<bibliomixed id="bib.castleengine.texcoordbounds">
  <abbrev>X3D TexCoord Bounds</abbrev>
  <firstname>Michalis</firstname> <surname>Kamburelis</surname>.
  <title><emphasis>Tex coord generation dependent on bounding box</emphasis></title>.
  <pubdate>2010</pubdate>.
  <bibliomisc>See <ulink url="http://castle-engine.sourceforge.net/x3d_extensions.php#section_ext_tex_coord_bounds" />.</bibliomisc>
</bibliomixed>

<bibliomixed id="bib.castleengine.projectivetexturing">
  <abbrev>X3D Projective Texturing</abbrev>
  <firstname>Michalis</firstname> <surname>Kamburelis</surname>.
  <title><emphasis>Projective texture mapping</emphasis></title>.
  <pubdate>2010</pubdate>.
  <bibliomisc>See <ulink url="http://castle-engine.sourceforge.net/x3d_extensions_shadow_maps.php#section_texture_projective" />.</bibliomisc>
</bibliomixed>

<bibliomixed id="bib.instantreality.noisetex">
  <abbrev>NoiseTexture</abbrev>
  <author><othername>Instant Reality</othername></author>.
  <title><emphasis>NoiseTexture</emphasis></title>.
  <bibliomisc>See <ulink url="http://doc.instantreality.org/documentation/nodetype/NoiseTexture/" />.</bibliomisc>
</bibliomixed>

</bibliography>

</book>
