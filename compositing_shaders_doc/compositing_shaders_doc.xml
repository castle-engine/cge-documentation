<?xml version='1.0'?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.4//EN"
  "/usr/share/sgml/docbook/dtd/xml/4.4/docbookx.dtd">

<!--
  Offline version of this DTD (as installed from Debian testing package) is
  "/usr/share/sgml/docbook/dtd/xml/4.4/docbookx.dtd"
  Online version of this DTD is
  "http://www.oasis-open.org/docbook/xml/4.4/docbookx.dtd"
-->

<book>

<bookinfo>
  <title>Compositing Shaders in X3D</title>
  <author>
    <firstname>Michalis</firstname>
    <surname>Kamburelis</surname>
  </author>
  <copyright>
    <year>2011</year>
    <holder>Michalis Kamburelis</holder>
  </copyright>
  <legalnotice><para>You can redistribute and/or modify
    this document under the terms of the
    <ulink url="http://www.gnu.org/licenses/gpl.html">GNU General Public
    License</ulink> as published by
    the Free Software Foundation; either version 2 of the License, or
    (at your option) any later version.</para>
  </legalnotice>
</bookinfo>

<!-- TODO: Title page, with above <bookinfo>,
  and "Ph.D. thesis" text,
  and Institute of Computer Science, University of WrocÅ‚aw, Poland
  and promotor,
  and maybe some image?
  add links to my pages (castle-eng and ~michalis)
-->

<preface id="abstract">
<title>Abstract</title>

<para>We present a new approach for implementing effects using the GPU shading languages.
Our effects seamlessly cooperate with each other and with
the shaders used internally by the 3D application.
Thus the effects are reusable, work in various combinations
and under all lighting and texture conditions.
%This makes the GPU shaders more usable for 3D content authors.
We have designed our effects to fit naturally in 3D scene graph formats,
in particular we present a number of extensions to the X3D standard.
Our extensions nicely integrate shader effects with X3D
<!-- groups, -->
concepts like shapes, light sources and textures.
</para>

<!--
%% The browser implementation may also gain from using the same approach
%% for composing internal shaders.
-->
</preface>

<chapter id="chapter.overview">
<title>Overview</title>

<para>X3D \cite{x3d:spec} is an open standard for representing interactive 3D models,
with many advanced graphic features.
</para>

<para>The X3D \textit{Programmable shaders component} \cite{x3d:shaders}
(part of the X3D standard) defines how \emph{shaders} can be assigned
to particular shapes. % and how they interact with other X3D features.
\emph{Shaders} are programs usually executed on the graphic processor unit
(GPU). They control the per-vertex and per-pixel processing,
for example summing the lights contribution
and mixing the texture colors. The authors
can create and assign shaders to shapes, which makes
a myriad of interesting graphic effects possible in X3D models.
</para>

<para>The shaders designed using the standard nodes
\textit{replace} the normal rendering functionality, not \textit{enhance} it.
This reflects the underlying API, like OpenGL or Direct3D.
The 3D libraries, in turn, follow the hardware idea that shader code
should be a complete and optimized program
designed for rendering a particular shape.
</para>

<para>We argue that a different approach is needed in many situations.
Authors usually would like to keep the normal rendering features working
and only add their own effects. The 3D renderer
implementation usually already has an extensive internal shaders system
and the authors want to depend on these internal shaders
to do the common job.
</para>

<para>As an example, consider this simplified lighting equation:
$$ \sum_{l\in Lights} shadow(l) * light\_color(l, material, normal(point)) $$
%% The \textit{shadow} function returns values in the [0..1] range,
%% scaling the light color. If the object is not in the shadow, it returns 1.
%% The \textit{normal} function returns a normal vector at given point.
Different effects want to change various parts of this equation,
without touching the others.
For example, the \textit{shadow} function may check a shadow map pixel,
or (when shadow map is not available) always return 1.
The \textit{normal} function may take the vector straight from
the geometry description, or calculate it using a texture value (classic bump mapping).
See figure \ref{figure.bump_mapping_shadows}.
The \textit{light\_color} function may be replaced to use different
lighting models.
% (Phong, Ward, Cook-Torrance and so on).
Sometimes it makes sense to change these functions
for all the light sources and sometimes only a specific light source
should behave differently.
Our approach allows you to do everything mentioned here.
%% by inserting a piece
%% of custom shader code into a calculation of a particular function.
%on a particular object.
</para>

<figure id="figure.bump_mapping_shadows">
  <title>Japanese shrine model with more and more effects applied:
Phong shading (per-pixel lighting), bump mapping, shadows from two lights.
The model is based on \texttt{http://opengameart.org/content/shrine-shinto-japan}.
</title>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/rhan_shrine_0.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/rhan_shrine_0.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/rhan_shrine_1_per_pixel_lighting_mini.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/rhan_shrine_1_per_pixel_lighting.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/rhan_shrine_2_bump_mapping_mini.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/rhan_shrine_2_bump_mapping.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/rhan_shrine_3_shadow_1st_mini.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/rhan_shrine_3_shadow_1st.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/rhan_shrine_4_shadow_2nd_mini.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/rhan_shrine_4_shadow_2nd.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/rhan_shrine_5_everything_mini.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/rhan_shrine_5_everything.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
</figure>

<para>We present a system for creating effects by essentially compositing
pieces of a shader code. All the effects defined this way effortlessly
cooperate and can be combined with each other and with application internal
shaders. This makes shader programs:</para>

<para>\begin{enumerate}
\item Much easier to create. We can jump straight into the implementation
  of our imagined algorithm in the shader.
  We are only interested in modifying the relevant shader calculation
  parameter. We do not need to care about the rest of the shader.

\item Much more powerful. Our effect
  immediately cooperates with absolutely every normal feature of X3D rendering.
  This makes the implemented effect useful for a wide range of real uses,
  not only for a particular situation or a particular model (as it often happens
  with specialized shader code).
  All X3D light sources, textures, even other shader effects,
  are correctly applied.
\end{enumerate}
</para>

<para>It is important that we still keep
the full power of a chosen GPU shading language.
We deliberately do not try to invent here a new language, or wrap existing
language in some cumbersome limitations.
%% This is most flexible for authors,
%% and it also allows an easy implementation --- there is no need for any complex
%% shading language processing inside the application.</para>

</chapter>

<chapter id="chapter.previous_work">
<title>Motivation and previous work</title>

<para>The most popular real-time shading languages right now are
OpenGL \texttt{GLSL} \cite{glsl:book}, NVidia \texttt{Cg} and Direct 3D \texttt{HLSL}.
They do not provide a ready solution for connecting shaders from independent sources.
The \texttt{CgFX} and HLSL \texttt{.fx} files encapsulate shading language code
in \emph{techniques} (for various graphic card capabilities)
and within a single technique specify operations for each rendering pass.
In neither case can we simply connect multiple shader source code files
and expect the result to be a valid program.</para>

<para>The X3D \textit{Programmable shaders component} \cite{x3d:shaders}
makes the three shading languages mentioned above available to X3D authors.
Complete shader code may be assigned to specific shapes.
Although it does not offer any way of compositing shader effects,
%the point of this component
%is to expose functionality that maps straightforward to graphic APIs like OpenGL.
this component is still an important base for our work. It defines
how to comfortably keep shader code inside X3D nodes. It also shows
how to pass uniform values (including textures) to the shaders.</para>

<para>An old solution to combine effects, used even before the shading languages,
is a multi-pass rendering. Each rendering pass adds or multiplies
to the buffer contents, adding a layer with desired effect.
However, this is expensive --- in each pass we usually have to repeat
some work, at least transforming and clipping the geometry.
It is also not flexible --- we can only modify
the complete result of the previous pass.
%% In our work, we want to allow a single rendering pass to be as
%% powerful as it can.
Arranging shader functions in a pipeline has similar disadvantages
as multi-pass rendering, except there's no speed penalty in this case.</para>

<para>Common approach for writing a flexible shader code is to create
a library of functions and allow the author to choose and compose them
in a final shader to achieve the desired look. But this approach is very limited,
as we cannot modify a particular calculation part without
replicating the algorithm outside of this calculation.
For example, if we want to scale the light contribution by a shadow function,
we will have to also replicate the code iterating over the light sources.</para>

<!--
<para>Another common solution is to arrange shaders in a pipeline, where one
shader processes the result of another. This can be visualized as
layers of materials, where each layer modifies the previous
color. It is actually similar to a multi-pass rendering approach,
except we do not lose speed on repeating the geometry transformation work.
Still it suffers from the same limitations, as we cannot change
the calculation within an existing layer, without replicating the whole
algorithm of this layer. </para>
-->

<!-- (see also http://groups.google.com/group/blendertorenderman/browse_thread/thread/aaf07831b91be9db?pli=1 , confirms my findings) -->

<para>Sh (\URL{http://libsh.org/}, \cite{sh:book})
allows writing shader code (that can run on GPU) directly inside a
C++ program.
%% For this, Sh extends the C++ language (through C++
%% operator overloading and macros tricks).
It allows an excellent
integration between C++ code and shaders, hiding the ugly details of
passing variables between normal code (that executes on CPU) and
shader code (that usually executes on GPU). We can use
object-oriented concepts to create a general shader that can
later be extended, for example by overriding virtual
methods. However, this is a solution closely coupled with C++. It's
suitable if we have a 3D engine in C++, we want to use it in
our own C++ program and extend its shaders. Our solution is simpler,
treating shader effects as part of the 3D content and can
be integrated into a renderer regardless of its programming language.
We do not need a C++ compiler to generate a final GPU shader
and users do not need to be familiar with C++.</para>

<para>OGRE (\URL{http://www.ogre3d.org/}), an open-source 3D engine written in C++, has a system
for adding shader extensions (see \cite{ogre:shader}). Its idea is similar
to our system (enhance the built-in shaders with our own effects),
however the whole job of combining a shader is done by operating
on particular shader by C++ code. The developer has to code
the logic deciding which shaders are extended and most of the specification
about how the extension is called is done in the C++ code.
This has the nice advantage of being able to encapsulate some fixed-function
features as well, however the whole system must be carefully controlled by
the C++ code.
In our approach, we allow the authors to write direct shading
language code quickly and the integration is built inside appropriate X3D nodes.</para>

<para>AnySL \cite{anysl} allows to integrate internal renderer shaders
with user shaders, by introducing a new shader language.
%% This has
%% advantages (hides the differences between GPU shading languages like
%% \texttt{GLSL} and \texttt{HLSL}), but also
%% On the other hand, we do not introduce
%% a new shader language, which is both an advantage (easy implementation,
%% easier to learn) and disadvantage (we do not hide differences e.g. between
%% ).
%% We strive to do something more and allow effortless
%% integration between many user shaders.
%%
%% We also try to be simpler as we do not
%% introduce any new shading language. On the other hand, the disadvantage
%% of our approach is that we do not hide the differences between various shading languages.
%% User effects have to be implemented in the same GPU shading language
%% that is used by the renderer.
</para>

<para>Spark \cite{spark} is a recent work presenting a new language to develop
composable shaders for GPU.</para>

<para>%% \cite{web3d2010:declarativeshader} presents a declarative approach
%% to an advanced shader in X3D. However, it only allows a fixed set
%% of functionality, kind od ``advanced and exhanced material''.
%% It does not expose any shader functionality to the authors.
%% It merely allows the authors to use some advanced algorithms that in practice
%% will be usually implemented by shaders inside the application.
</para>

<para>At the end, we would like to mention a solution from a completely
different domain, that is surprisingly similar to ours in some ways.
Drupal (\URL{http://drupal.org/}),
an open-source CMS system written in PHP,
has a very nice system of modules. Each module
can extend the functionality of the base system (or other module)
by implementing a \textit{hook}, which is just a normal PHP function
with a special name and appropriate set of parameters. Modules can also define
their own hooks (for use by other modules) and invoke them when appropriate.
This creates a system where it's trivially easy to define new hooks
and to use existing hooks.
Many modules can implement the same hook and cooperate without any problems.
%% The whole hook system is defined completely in PHP, as it's a scripting
%% language and we can query the list of loaded functions by name,
%% and call function by its name.
Drupal approach is quite similar to our
core idea of combining effects. Our effects are similar to
Drupal's modules and our ``plugs'' are analogous to Drupal hooks.</para>

<para>%% Our effects can define functions with special names to enhance
%% the standard shader behavior, just like Drupal modules can define functions
%% to act on an event from another module.
%% We can also define new plugs, for other effects to use.
%% Of course we also have some special problems
%% (shading language is quite far from a scripting language,
%% so calling the plugs must be implemented by text replacements)
%% and some special opportunities (we can define effects at
%% the appropriate nodes of X3D, like textures and lights sources,
%% as we do not want to throw all the effects in one bag).</para>

<!--
% OpenSceneGraph:
% http://www.openscenegraph.org/projects/osg/wiki/Support/Tutorials/ShadersParameters
% http://www.openscenegraph.org/projects/osg/wiki/Support/Tutorials/ShadersIntroduction
% http://mew.cx/osg_glsl_july2005.pdf
% I see no way to connect shaders?
%
% Irrlight - - - also no way to connect shaders?
%
% Blender Game Engine: no way to connect shaders, Python code can
% set the final (complete) shader source only?
% http://download.blender.org/documentation/GE/Blender.htm
% http://www.blender.org/development/release-logs/blender-248/realtime-glsl-materials/
% See also source, inside source/gameengine/:
% ./Ketsji/BL_Shader.h
% ./Ketsji/BL_Shader.cpp
% ./Ketsji/BL_BlenderShader.h
% ./Ketsji/BL_BlenderShader.cpp
-->

</chapter>

<chapter id="chapter.plugs">
<title>Extending the shaders with plugs</title>

<para>The core idea of our approach is that the base shader code defines
points where calls to user-defined functions may be inserted. We call
these places \textit{plugs}, as they act like sockets where logic
may be added. Each plug has a name and a given set of parameters.
The effects can use special function names, starting with \texttt{PLUG\_}
and followed by the plug name. These declarations will be found
and the renderer will insert appropriate calls to them from the base shader.</para>

<para>A trivial example of an effect that makes colors two times brighter
is below. This is a complete X3D file, so you can save
it as \texttt{test.x3dv} and open with any tool supporting our
extensions, like \texttt{view3dscene}.</para>

<para>
\begin{Verbatim}[commandchars=\\\{\},frame=single,fontsize=\small]
#X3D V3.2 utf8
PROFILE Interchange
Shape \{ appearance Appearance \{
  material Material \{ \}
\textbf{  effects Effect \{}
\textbf{    language "GLSL"}
\textbf{    parts EffectPart \{}
\textbf{      type "FRAGMENT"}
\textbf{      url "data:text/plain,}
\textbf{      \textit{void PLUG_texture_apply(}}
\textbf{      \textit{  inout vec4 fragment_color,}}
\textbf{      \textit{  const in vec3 normal)}}
\textbf{      \textit{\{}}
\textbf{      \textit{  fragment_color.rgb *= 2.0;}}
\textbf{      \textit{\}}" \} \}}
\} geometry Sphere \{ \} \}
\end{Verbatim}</para>

<para>Our extensions to X3D are marked with the bold font in the example above.
The GLSL code inside our extensions is marked with the italic font.
%% GLSL function names starting with \texttt{PLUG_} are special,
%% they will be automatically called at the appropriate place with appropriate
%% parameters from the final (automatically generated and used) shader.
The special GLSL function name \texttt{PLUG\_texture\_apply}
indicates that we use the \texttt{texture\_apply} plug.
This particular plug is called right after applying the textures,
and is the simplest way to ``just modify the pixel color''.
%% The \texttt{texture\_apply} plug in
%% the renderer internal shader. This particular plug,
%% the \texttt{PLUG\_texture\_apply}, is called after the normal texture colors
%% are applied, but before the alpha test and is a usual place
\texttt{fragment\_color} is an \texttt{inout} parameter, by modifying it
we modify the color that will be displayed on the screen.</para>

<para>A reference of all the plugs available in our implementation
is on \URL{http://castle-engine.sourceforge.net/compositing_shaders.php}.
For each plug, like this \texttt{PLUG\_texture\_apply},
we define a list of parameters
%(they have to be declared exactly the same in an effect),
and when it is called.</para>

<para>Many usage scenarios are possible:</para>

<!--\begin{enumerate}-->

<para>\item The \texttt{Effect} nodes may use plug names
defined inside the renderer internal shaders. This is the most usual case.
It allows the authors to extend or override a particular shading parameter.</para>

<para>\item The \texttt{Effect} nodes may also use the plug names defined
in the previous \texttt{Effect} nodes on the same shape.
It is trivially easy (just add a ``magic'' comment) to define
plugs in your own shader code. This way your own effects
can be customized.</para>

<para>\item Inside the renderer implementation, the same approach can be used
to implement some internal effects.
We have reimplemented many internal effects of our engine,
like the fog, shadow maps (see \cite{vrmleng:shadowmaps})
and the bump mapping to use our ``plugs'' approach.
This made their implementation very clean, short
and nicely separated from each other.
%% It also proves that
%% the authors have the power to implement such effects easily by themselves.
</para>

<para>%% without any traditional hassles. For example, bump mapping can be
%% achieved using standard \texttt{ComposedShader} as well,
%% but then you have to write all this ``boilerplate'' code to also deal
%% with all the possible lighting and textures configurations.
%% Well, the renderer is still useful to calculate nice tangent vectors,
%% although an authoring program could generate GLSL attributes for them as well.</para>

<para>%% Same thing with shadow maps, they only plug to the \texttt{light\_scale}
%% calculation of appropriate light.</para>

<!-- \end{enumerate} -->

<para>Actually, there are even more possibilities.
We have been talking above about the ``renderer internal shaders'',
but the truth is a little more flexible.
When you place a standard shader node
(like a \texttt{ComposedShader} node for GLSL shaders) on the
\texttt{Appearance.shaders} list,
then it replaces the internal renderer shaders.
If you define the same (or compatible) plugs inside your shader,
then the internal renderer effects are even added to your own
shader. Of course user effects are added to your shader too.
This way even the standard X3D shader nodes become more flexible.
Note that if you do not define any plugs inside your \texttt{ComposedShader} node,
it continues to function as before --- no effects
will be added.</para>

<section id="section.effect_node">
<title>Effect node</title>

<para>New \texttt{Effect} node holds information about
the source code and uniform values specific to a given effect.
The node specification below follows the style of
the X3D specification \cite{x3d:spec}.</para>

<para>
\begin{mycode}
\underline{Effect : X3DChildNode}
\begin{Verbatim}[commandchars=\\\{\},fontsize=\small]
SFString [] \codeem{language} ""
  # Language like "GLSL", "CG", "HLSL".
  # This effect will be used
  # only when the base renderer shader
  # uses the same language.
SFBool [in,out] \codeem{enabled} TRUE
  # Easily turn on/off the effect.
MFNode [] \codeem{parts} [] # EffectPart
  # Source code of the effect.

# A number of uniform values may also be
# declared inside this node.
\end{Verbatim}
\end{mycode}
</para>

<para>Inside the \texttt{Effect} node a number of uniform values may be defined,
passing any X3D value to the shader. Examples include passing
current world time or a particular texture to the shader.
Uniform values are declared exactly like described in the standard
X3D \textit{Programmable shaders} component \cite{x3d:shaders}.</para>

<para>
%% , just like
%% # for ComposedShader node

% Comments for ``enabled'':
%% # You could also remove/add the node
%% # from the scene, but often toggling
%% # this field is easier for scripts.
</para>

<para>The effect source code is split into a number of parts:</para>

<para>
\begin{mycode}
\underline{EffectPart : X3DNode, X3DUrlObject}
\begin{Verbatim}[commandchars=\\\{\},fontsize=\small]
SFString [] \codeem{type} "VERTEX"
  # Like ShaderPart.type:
  # allowed values are
  # FRAGMENT | VERTEX | GEOMETRY.
MFString [] \codeem{url} []
  # The source code, like ShaderPart.url.
\end{Verbatim}
\end{mycode}

  %% # May come from an external file (url),
  %% # or inline (following "data:text/plain,").
  %% # In XML encoding, may also be inlined in CDATA.
</para>

<para>Inside the effect part source code, the functions that enhance
standard shaders behavior are recognized by names starting with \texttt{PLUG\_}.
Of course other functions can also be defined and used.
Uniform variables can be passed to the effect,
also varying variables can be passed between the vertex and fragment
parts, just like with standard shader nodes.
</para>

<para>
In a single \texttt{EffectPart} node, many \texttt{PLUG\_}
functions may be declared. However, all plug functions must be declared in the appropriate
effect type. For example, the \texttt{texture\_apply} plug cannot be used
within a \texttt{VERTEX} shader.
If the effect requires some processing per-vertex and some per-fragment,
it is necessary to use two \texttt{EffectPart} nodes, with different types.
This allows to implement our system for
%% While this may seem like an arbitrary limitation,
%% this reflects how shader parts are declared in
shading languages with
separate namespaces for vertex and fragment parts (like GLSL).
A single part may declare many variables and functions,
but it must be completely contained within a given shader type.
</para>

<para>Note that it is completely reasonable to have an \texttt{EffectPart} node
with source code that does not define any \texttt{PLUG\_xxx} functions.
Such \texttt{EffectPart} node may be useful for defining shading language
utility functions, used by other effect parts.
</para>

<para>For shading languages that have separate compilation units
(like the \emph{OpenGL Shading Language}) the implementation may choose to place
each effect part in such separate unit. This forces the shader code to be
cleaner, as you cannot use undeclared functions and variables from other parts.
It also allows for cleaner error detection (parsing errors will be detected
inside the given unit).
</para>

<para>%% We have also considered and rejected a different approach to use plugs.
%% In that approach, the plug name was indicated by a new field of
%% the \texttt{EffectPart} node, not by a special \texttt{PLUG\_} function name
%% inside the shader code.
%% However, the implementation may need to know the full declaration
%% of a plug function, to make a forward or external declaration of it.
%% One way to overcome this problem was to require repeating this declaration
%% in another field. Another solution was to split shader code into more
%% parts (for example, one part declares the uniform variables, one part declares
%% the plug function, one part defines the function body and so on).
%% Both approaches seemed uncomfortable for authors
%% and they didn't really offer a simpler implementation, so we dropped this idea.
%% The current approach, to find the declarations of \texttt{PLUG\_xxx} functions
%% inside a complete shader code, is easy to implement and results in clean
%% shader code of the effects. It also allows us to naturally use
%% the separate compilation units in case of GLSL.</para>

<para>%% Detecting special \texttt{PLUG\_} function names inside the shader code
%% is trivial, and it turned out to be the best approach to design our effects.
%% This means that each effect code is clean, and can be compiled separately
%% from others. It allows us to naturally use
%% the \textit{separate compilation units} in case of GLSL implementation.</para>

</section>

<section id="section.effects_on_shape">
<title>Effects for particular shapes</title>

<para>There are various places where an \texttt{Effect} node may be used.
To apply an effect for a given shape appearance, it can be placed
on the new \texttt{Appearance.effects} list:</para>

<para>\begin{mycode}
\underline{Appearance}
\begin{Verbatim}[commandchars=\\\{\},fontsize=\small]
MFNode [] \codeem{effects} [] # Effect
\end{Verbatim}
\end{mycode}</para>

<para>All the effects on this list (with suitable language) will be used.
%% Note that this is different
%% than the \texttt{Appearance.shaders}, which chooses only one shader.
%% For effects, we choose all of them.
This allows authors to define a library of independent shader effects
and then trivially pick desired effects for each particular shape.
Simply placing two effects on the \texttt{Appearance.effects} list
makes them cooperate correctly.
%% . This also allows to
%% define a library of effects, that can be composited without any work
%% needed by user.</para>

<figure id="figure.toon_and_fresnel">
  <title>Toon and Fresnel effects combined.</title>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/fresnel_and_toon.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/fresnel_and_toon.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
</figure>

<para>Note that all introduced nodes benefit from X3D mechanism to reuse the nodes
by reference (the \texttt{DEF} / \texttt{USE} keywords). Reusing the
\texttt{Effect} nodes
is most natural and allows to combine existing effects in any desired way.
Reusing the \texttt{EffectPart} nodes is also useful, when some effects
would like to share a particular piece of code. For example,
the same \texttt{EffectPart} node, with a library of useful
shading language functions, may be used for many effects.</para>

<figure id="figure.fog">
  <title>Volumetric fog scene: 1) No fog; 2) No lighting; 3) Lights and fog.
Note that the fog is assumed to have its own ambient lighting,
so it colors the image even in the 2) case.</title>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/volumetric_animated_fog_no_fog.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/volumetric_animated_fog_no_fog.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/volumetric_animated_fog_no_light.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/volumetric_animated_fog_no_light.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/volumetric_animated_fog_all.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/volumetric_animated_fog_all.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
</figure>

</section>

<section id="section.effects_on_group">
<title>Effects for a group of nodes</title>

<para>The \texttt{Effect} node is a descendant of the abstract \texttt{X3DChildNode}.
As such it can be placed directly within X3D grouping nodes like
\texttt{Group}, \texttt{Transform} and at the top level of the X3D file.
Such effect will apply to all the shapes within the given group.
The scope rules follow the X3D conventions for other nodes,
like pointing device sensor nodes and \texttt{LocalFog}.</para>

<para>The \texttt{LocalFog} example is worth emphasizing. Using our system,
an X3D viewer can implement the \texttt{LocalFog} node as a prototype
that expands to our \texttt{Effect} node. This results in a 100\% correct
and easy implementation of the standard \texttt{LocalFog} node.</para>

<para>As one of the demos, we have implemented a realistic
animated volumetric fog, where the fog density is stored in
a 3D smooth noise texture (idea from \cite{humus:volumetricfog}).
In a fragment shader, the 3D~texture is sampled
along the line between the camera and pixel position in the 3D~space. This makes a very
convincing effect of a dense fog. The \texttt{Effect} node with
appropriate shader code is placed at the top level of the X3D file,
so it simply works for all shapes. See figure \ref{figure.fog}.</para>

</section>

<section id="section.effects_on_lights">
<title>Light sources effects</title>

<para>The nice feature of our system is that effects can be attached to various
types of objects, not just shapes. For example a particular light source
may have a shader effect assigned.
This allows to modify the contribution of a given light.
For example the spot light shape can be modified, possibly
based on some texture information (see figure \ref{figure.fancy_spot}).
Or a different lighting model may be implemented, like anisotropic Ward
or Cook-Torrance.
To make this possible, the \texttt{effects} field is added to every light node:</para>

<para>\begin{mycode}
\underline{X3DLightNode}
\begin{Verbatim}[commandchars=\\\{\},fontsize=\small]
MFNode [] \codeem{effects} [] # Effect
\end{Verbatim}
\end{mycode}</para>

<figure id="figure.fancy_spot">
  <title>Textured spot light with shadow.</title>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/fancy_light_spot_shape.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/fancy_light_spot_shape.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
</figure>

<para>%% , or even replace the default
%% calculation of the light source contribution. In the second case,
%% the default calculation will not even be used in the shader,
%% so it will not slow down the calculation without a reason.</para>
</section>

<section id="section.effects_on_texture">
<title>Texture effects</title>

<para>Just like the light sources, also each texture node may define its own effects:
</para>

<para>\begin{mycode}
\underline{X3DTextureNode}
\begin{Verbatim}[commandchars=\\\{\},fontsize=\small]
MFNode [] \codeem{effects} [] # Effect
\end{Verbatim}
\end{mycode}</para>

<para>\texttt{X3DTextureNode} is an ancestor for all the standard texture nodes,
like the \texttt{ImageTexture}. This allows to modify any X3D texture
by shader effects.
A plug \texttt{texture\_color} may be used to change the texture color,
taking into account the current texture coordinates and other information.</para>

<section id="section.procedural_textures">
<title>Procedural textures</title>

<para>A new X3D node \texttt{ShaderTexture} is available for creating
procedural textures using the GPU shading languages.
%% This is suitable
%% if the texture is defined completely using the shading language.
The texture contents are not stored anywhere (not even on GPU)
and the renderer does not manage any texture resources.
From a GPU point of view, there is no texture.
%\footnote{But the spoon is real,
%we swear.}.
There is only a shader function that generates colors
based on some vectors. By wrapping such function inside
the \texttt{ShaderTexture} node, it can be treated exactly like other textures
in the scene. In particular, texture coordinates
(explicit or generated) can be comfortably provided
for the procedural texture.
Effectively, it behaves like a normal texture node, with all the related
X3D features.</para>

<para>The new texture node specification:</para>

<para>\begin{mycode}
\underline{ShaderTexture : X3DTextureNode}
\begin{Verbatim}[commandchars=\\\{\},fontsize=\small]
MFNode [] \codeem{effects} [] # Effect
SFString [] \codeem{defaultTexCoord} "BOUNDS2D"
  # ["BOUNDS2D"|"BOUNDS3D"]
\end{Verbatim}
\end{mycode}</para>

<para>%% Actually, the \texttt{effects} field is already defined at
%% the \texttt{X3DTextureNode} class (see above).  It is mentioned here
%% for completeness.</para>

<para>An effect overriding the \texttt{texture\_color} plug
should be included, otherwise texture colors are undefined.
Our implementation
sets the default texture color to pink (RGB(1,~0,~1)), so it stands out,
reminding author to override it.</para>

<para>The texture coordinates, or the algorithm to generate them,
can be explicitly specified, just like for any other texture in X3D.
%% . This follows the usual rules for all
%% when a \texttt{X3DTextureCoordinateNode} node is placed
%% inside the geometry \texttt{texCoord} field.
%% Both explicit texture coordinate lists (\texttt{TextureCoordinate}
%% \texttt{TextureCoordinate3D}, \texttt{TextureCoordinate4D})
%% and the coordinate generator nodes
%% (like \texttt{TextureCoordinateGenerator}) are suitable.
%% %% , \texttt{ProjectedTextureCoordinate}
%% Note that our engine has some extensions to allow
%% the \texttt{"BOUNDS2D"} and \texttt{"BOUNDS3D"} values to be also
%% used for the \texttt{TextureCoordinateGenerator.mode} field, see
%% \cite{vrmleng:texcoordbounds}.
When the texture coordinates are not explicitly given,
the \texttt{defaultTexCoord} field determines how they are generated.
\texttt{"BOUNDS2D"} generates 2D texture coordinates,
adapting to the two largest bounding box sizes
(the 3rd texture coordinate is always 0). This is most comfortable
when the texture color depends only on the XY components of the texture coordinate.
The precise behavior
of \texttt{"BOUNDS2D"} follows the X3D \texttt{IndexedFaceSet} specification
and the precise behavior of \texttt{"BOUNDS3D"} is described in
the \textit{Texturing3D} component of the X3D specification.</para>

<para>%%  (section \textit{"Texture coordinate generation for primitive objects"})
%%   is used.
%%   This adapts 3D texture coordinates to the bounding box sizes.
%%   It's most suitable for 3D textures (the 4th texture coordinate
%%   component can be ignored; or the 4D vector may be treated as homogeneous, as \texttt{"BOUNDS3D"} will always
%%   set the 4th component to 1).</para>

<!-- %% \end{enumerate} -->

<para>%% The idea is that using a \texttt{ShaderTexture} should be as comfortable
%% as any other texture node.</para>

<para>%% Projective texture mapping by \texttt{ProjectedTextureCoordinate}
%% is also our extension, see \cite{vrmleng:projectivetexturing}.</para>
</section>

<section id="section.when_use_shader_texture">
<title>When to use the ShaderTexture</title>

<para>For textures other than the \texttt{ShaderTexture},
when the \texttt{texture\_color} plugs are called,
the internal shaders have already calculated the initial texture
color by actually sampling the texture image. This is useful if you
want to modify this color. If you'd rather ignore the normal
sampled color, and always override it with your own, consider using
the special \texttt{ShaderTexture} node instead. Using
a normal texture node (like \texttt{ImageTexture}) for this
would be uncomfortable, as you would have to load a dummy texture image,
and the shaders could (depending on optimization) waste some time
on calculating a color that will be actually ignored later.</para>

<para>Note that in all cases (effects at \texttt{ImageTexture},
at \texttt{ShaderTexture}, etc.) you can always use additional
textures inside the effect. Just like inside a standard \texttt{ComposedShader},
you can declare an \texttt{SFNode} field inside an \texttt{Effect}
to pass any texture node to the shader as a uniform value.
This allows to combine any number of textures inside an effect.
The only difference
between \texttt{ShaderTexture} and other textures is what the system
does automatically for you, that is what color is passed
to the first \texttt{texture\_color} plug.</para>

<figure id="figure.shader_texture_edge_detection">
  <title>ShaderTexture doing an edge detection operation on a normal ImageTexture.</title>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/shader_texture_edge_detection.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/shader_texture_edge_detection.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
</figure>

</section>

<section id="section.filtering">
<title>Independence from texture filtering</title>

<para>Note that the shader effects for textures are calculated at each screen fragment
(not at each texel). So the effects are not concerned about the texture size
or texture filtering options. We can just use the interpolated texture
coordinates in the \texttt{texture\_color} plug.</para>

<figure id="figure.shader_texture_no_filtering_problems">
  <title>Yellowish arc is done by a texture effect, and so is not
    affected by the pixelated look of the base image texture.</title>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/shader_texture_no_filtering_problems.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/shader_texture_no_filtering_problems.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
</figure>

</section>

</section>

</chapter>

<chapter id="chapter.custom_plugs">
<title>Defining custom plugs</title>

<para>In a shader code, new plug may be defined by a magic comment:</para>

<para>\begin{mycode}
\begin{Verbatim}[commandchars=\\\{\},fontsize=\small]
/* PLUG: name (param1, param2, ...) */
\end{Verbatim}
\end{mycode}</para>

<para>This defines a point where calls to user functions declared as
\texttt{PLUG\_name} will be inserted. They will be called with given
parameters.</para>

<para>Many effects may use the same \texttt{PLUG\_name}.
Even within a single effect, the same \texttt{PLUG\_name} may be used
many times. All the \texttt{PLUG\_name} functions
will be uniquely renamed to not collide with each other.</para>

<para>The calls will be added in the order they are specified on the
\texttt{effects} list. More precisely, the most local effects
(at light sources and textures) are called first, then the effects
at shape appearance, and finally the effects inside the grouping nodes.
Although, preferably, for most effects this order will not matter.</para>

<para>A plug is often defined to allow modifying some parameter
repeatedly (like adding or modulating the fragment color),
so one or more of the parameters are often allowed to be handled
as \texttt{inout} values.</para>

<para>The same plug name may be defined many times in the source shader.
This means that a single \texttt{PLUG\_xxx} function will be called
many times. For example, this is useful when the algorithm is naturally
expressed as a loop, but it had to be unrolled for shader source
(for example, to slightly tweak some loop iterations).
The plug names that are available per-light source and per-texture
are an example of this.
%% If you use the \texttt{PLUG\_texture\_color}
%% inside \texttt{Appearance.effects}, you change the color of all
%% the textures (even shader textures).
%% Not really available, as params to texture\_color differ.
Using the \texttt{PLUG\_light\_scale}
inside \texttt{Appearance.effects}, the intensity
of all the light sources on the given shape can be changed. Contrast this with using
the same \texttt{PLUG\_light\_scale} inside a \texttt{X3DLightNode.effects},
where only the given light node contribution is changed.</para>

<para>Currently all the plugs must be procedures, that is their result type
must be declared as \texttt{void}. We have been considering
a possibility of functions, where part of the calculation may be replaced
by a call to a plugged function. While not difficult to implement,
this idea seems unnecessary after many tests.
Procedural plugs are easier to declare, as the call to the plug
may be simply inserted, while in case of function it will have to replace
some previous code. This also means that using a procedural plug
\textit{never} replaces or removes some existing code, which is a very nice
concept to keep. We want the effects to cooperate with each other,
not to ``hijack'' from each other some parts of the functionality.</para>

<para>New plugs can be defined inside the \texttt{Effect} nodes,
as well as inside the complete shaders (like standard
\texttt{ComposedShader} nodes).
In the first case, the plugs
are only available for the following effects of the same shape.</para>

<para>The advantage of using magic comments to define plugs is that
they can be ignored and a shader source remains valid.
This means that \texttt{ComposedShader} nodes can define custom plugs
and still work (although with no extra effects) even in X3D browsers
that do not support our extensions.</para>

<section id="section.forward_declarations">
<title>Forward declarations</title>

<para>Suppose we have an effect~$X$ that defines a new plug.
%, by includes a magic \texttt{/* PLUG: ... */} comment.
When this plug is used by another effect~$Y$,
then an appropriate function call is automatically inserted into the generated shader.
In the middle of the source code of effect~$X$,
a function defined in effect~$Y$ has to be called. This is the simplest
implementation of our plugs.
% Would be nice to have here a space for paragraph break...
Additionally, a forward or external declaration of the called function
may need to be inserted into the effect~$X$. That is because~$Y$
may be in a separate compilation unit (in case of GLSL),
or just defined lower in the code. In simple cases, such forward or external
declarations can be inserted right at the beginning of effect~$X$ code.
</para>

<para>Some shading language directives are required to be placed before
all normal declarations. For example, in case of the \emph{OpenGL shading language},
the \texttt{\#version} as well as some \texttt{\#extension} directives
must occur at the beginning of the shader code.
To handle such cases, another magic comment \texttt{/* PLUG-DECLARATIONS */}
is available.
If present, it signifies a place where forward or external declarations
should be inserted.</para>

<!-- %% because it may
%% These (forward or external) declarations are inserted at
%% the point of special \texttt{/* PLUG-DECLARATIONS */}
%% comment, or (when it is missing) simply at the beginning of shader source.
%% This applies in the same way to shader code inside an \texttt{EffectPart},
%% or inside standard X3D node like \texttt{ShaderPart}.

%% \texttt{/* PLUG-DECLARATIONS */} should be placed after such directives
%% and before any \texttt{/* PLUG: ... */} declarations.
-->

</section>

<section id="section.invalid_shader_code">
<title>Invalid shader code</title>

<para>The behavior is defined only if the provided shading language code
is a correct, self-contained code. The errors (like unterminated block)
%%  (``\texttt{\{}'' without matching ``\texttt{\}}'')
%% ,
%% or an unterminated comment)
may only be detected after the complete shader
is determined and compiled by the GPU.
It should be noted that for shading languages with separate compilation units,
the parsing errors can be at least reported always for the correct code piece
(effect part).</para>

<para>The \textbf{application does not need to parse the shader code} at any point.
Only a trivial text search in the code is necessary to detect the magic
plug function names and comments.
%% Still, an incorrect effect code may cause the whole shader to malfunction.
</para>

<!--
%% In all our practical tests, this approach didn't cause any problems.
%% Since each effect can be implemented separately, it can also be tested separately,
%% and in practice it's usually obvious where to look for the parsing error.

%% It should be noted however that in particularly nasty cases,
%% a deliberately poorly coded effect may cause troubles for other effects.
%% In particular, since you can use \texttt{\#define} and macros in your effect code,
%% you can do nasty tricks to break other effects. You can make them compile,
%% but function incorrectly. However, we do not consider
%% it a real problem. You really have to deliberately want to do something bad,
%% and be familiar with internals about how the shader is generated,
%% to achieve some particular weird behavior.
%% It does not happen by accident in our experience.
%% %% Moreover, you may need to use the internal knowledge
%% %% how the other effects are implemented (maybe how they are implemented
%% %% inside the browser).

%% Note that this isn't a security problem - - - bad shader code only breaks
%% rendering of a particular shape. Besides, X3D \texttt{ComposedShader} node allows users
%% to execute any shading language code anyway. So if there's anything dangerous
%% (for example a buggy OpenGL may cause the browser process to exit with
%% segmentation fault on some special shader code snippets),
%% you could do it without using our effects framework anyway.
-->
</section>
</chapter>

<chapter id="chapter.examples">
<title>Examples</title>

<para>Effects may define and use their own uniform variables, including textures,
just like the standard shader nodes. So we can combine any number of textures
inside an effect. As an example we wrote a simple effect that mixes a couple of
textures based on a terrain height (see figure \ref{figure.terrain}).
We could also pass any other uniform value to the effect, for example
passing the current time from an X3D \texttt{TimeSensor} allows to make
animated effects.</para>

<figure id="figure.terrain">
  <title>ElevationGrid with 3 textures mixed (based on the point height) inside the shader.</title>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/terrain.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/terrain.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
</figure>

<para>We can wrap 2D or 3D noise inside a \texttt{ShaderTexture}
(see figure \ref{figure.noise}).
A texture node like \texttt{NoiseTexture} from InstantReality
\cite{instant:noisetex}
may be implemented on GPU by a simple prototype using the \texttt{ShaderTexture}.
</para>

<figure id="figure.noise">
  <title>3D and 2D smooth noise on GPU, wrapped in a ShaderTexture.</title>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/noise.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/noise.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
</figure>

<para>\emph{Water} is very nice to implement with the help of our effects,
as a proper water simulation
is naturally a combination of a couple effects.
To simulate waves we want to vary vertex
heights, or vary per-fragment normal vectors (for best results,
we want to do both things).
We also want to simulate the fact that water has reflections and
is transparent. We have implemented a nice water using this approach,
with (initially) two independent effect nodes. See figure \ref{figure.water}.
Then we have tested two alternative
approaches for normal generation (take from pre-recorded series of normal-maps,
or calculate from a smooth 3D noise). They both generate normal
vectors in the tangent space, overriding a plug defined by yet another effect
that transforms normals into the eye space.
This way we have extracted all the common logic into a separate effect,
making it clear where the alternative normal generation methods differ
and what they have in common.</para>

<!--
%% Our approach also allowed us to easily implement and test
%% two alternative versions for generating water normals.
%% One approach was to take normals from the pre-recorded sequence of images
%% (encoded inside \texttt{MovieTexture},
%% with noise images generated by the \emph{Blender} renderer).
%% The second approach was to calculate normals on the GPU from
%% a generated smooth 3D noise. Thanks to our effects system,
%% we could immediately test our alternative normal vector approaches,
%% without touching the water reflection / refraction effect.
%% Moreover, the implementations of these two approaches are concerned
%% only with calculating the normal vectors in the object space.
%% They override a special plug of yet another effect, that transforms
%% these normal vectors into the eye space.
%% This way we have extracted all the common logic into a separate effect,
%% making it clear where the alternative versions differ and what they have
%% in common.
%% This was possible because one effect can define
%% new plug names, that can be used by the other effects.

%% (As for the results about which one is better: predictably, we showed
%% that using GPU noise is slower, requires a better GPU,
%% but also improves the quality noticeably. With GPU noise, there is no problem
%% with aliasing of the noise texture and the noise parameters can be adjusted
%% in real-time.)
-->

<figure id="figure.water">
  <title>Water using our effects: 1) Per-pixel lighting and bump mapping.
2) Per-pixel lighting and reflections and refractions (by a single environment cube map texture).
3) All effects.</title>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/water_shaders_0.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/water_shaders_0.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/water_shaders_1.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/water_shaders_1.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/water_shaders_2.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/water_shaders_2.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/water_shaders_3.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/water_shaders_3.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
</figure>

<para>
We also have plugs to change the geometry in object space.
%% Again, since the effect is integrated with all the browser shaders,
%% you only need to code a simple function to change the vertex positions
%% as you want. The effect instantly works with all the lighting and texturing
%% conditions.
Since the transformation is done on GPU, there's practically
no speed penalty for animating thousands of flowers in our test scene.
See figure \ref{figure.flowers}.
</para>

<figure id="figure.flowers">
  <title>Flowers bending under the wind, transformed on GPU in object space.</title>
  <mediaobject>
  <imageobject role="html"> <imagedata format="PNG" fileref="images/flowers.png" /> </imageobject>
  <imageobject role="fo">   <imagedata format="PNG" fileref="images/flowers.png" width="3in" contentwidth="3in" /> </imageobject>
  </mediaobject>
</figure>

<para>We would like to emphasize that all the effects demonstrated here
are theoretically already possible to implement using the standard
X3D \textit{Programmable shaders component} \cite{x3d:shaders}. However, such implementation
would be extremely cumbersome.
You would first have to implement all the necessary multi-texturing, lighting,
shadows, and other rendering features in a shader code.
This is a large work if we consider all the X3D rendering options.
Also note that a shader should remain optimized for a particular setting.
%% Actually, it isn't even possible, unless we can calculate some global options,
%% like which light sources and fog nodes affect the given shape.
The only manageable way to do this, that would work for all the lighting
and texturing conditions, is to write a shader generator program.
Which is actually exactly what our effects already do for you ---
the implementation of our effects constructs and links
the appropriate shader code, gathering the information from all the nodes
that affect the given shape. The information is nicely integrated
with X3D nodes, effects are specified at suitable nodes, and their
uniform values and attributes are integrated with X3D fields.</para>

<para>Many complete example models using our effects
are referenced from our page on
\URL{http://castle-engine.sourceforge.net/compositing_shaders.php}.
%% The relevant demos are mostly inside the \texttt{compositing\_shaders}
%% subdirectory, also the \texttt{water} subdirectory contains
%% the mentioned water effects.
You can open these examples using any of our engine tools,
like \texttt{view3dscene}.</para>

<!--

%% You can run \texttt{view3dscene} with \texttt{- -debug-log-shaders} command-line
%% option. Output will show you the final shader code generated,
%% and also the OpenGL log after linking the shaders.
%% %% Be sure to redirect the output to a file and you may want to test it first
%% %% with a simple scene with one shape - - - as the output may be quite large.
%% This is a useful way to learn about our shader rendering internals.

%% Another useful option to try in \texttt{view3dscene} is to switch to
%% \textit{View $\rightarrow$ Shaders $\rightarrow$ Enable For Everything} mode.
%% This will force shader rendering for all the shapes,
%% while by default we use shader rendering only for the shapes that
%% require particular effects (shaders by \texttt{ComposedShader}, effects
%% described in this paper, shadow maps and such).
%% Forcing shader rendering for everything allows to see
%% how our shaders implement the whole X3D lighting and texturing model.
%% It also forces all the lighting calculation to be done per-pixel, resulting
%% in perfect specular highlights and spot light shapes.

-->

</chapter>

<chapter id="chapter.implementation">
<title>Implementation notes</title>

<para>We have implemented all the X3D extensions described in this paper
for the \emph{OpenGL Shading Language} (GLSL).
However, we have designed our extensions
to be applicable to other shading languages as well (like Cg or HLSL)
and we believe they can be handled in a similar fashion.
In particular, we have tested that the \emph{separate compilation units}
concept of GLSL, while very useful, is not necessary for proper implementation
of our effects.
</para>

<!--
%% concept, that is specific to GLSL, is useful here:
%% it forces
%% cleaner shader code (you cannot use undeclared functions from other
%% shader parts) and it gives you better line numbers in error messages
%% (although a pre-processor directive like \texttt{\#line} could also be used for
%% this).

%% and we think that the same set of plugs will be useful for them - - - but it's just a theory.
%% An implementation of our effects for other shading languages may
%% find other opportunities for plugs.
%% In particular, we have tested that the \emph{separate compilation units}
%% of GLSL are not necessary for a correct implementation of our effects.
%% We also believe that most of our plugs (like ``do something in object space'',
%% ``do something in eye space'') are generic enough to be usable
%% with all shading languages.

%% for ph.d. uncomment:
%% Our approach does not cause any speed loss. Effects code is just
%% combined into the final shader code, without any transformations that
%% could make it slower. Our process of ``combining'' effects is essentially
%% adding function calls around. Fortunately, a function call has no speed
%% penalty. Existing shading languages are defined
%% such that functions can always be inlined (there is no recursion allowed,
%% and parameter qualifiers have simple interpretation),
%% and as far as we know they are actually always inlined by existing
%% shading language compilers.
-->

</chapter>

<chapter id="chapter.conclusion">
<title>Conclusion</title>

<para>We show a new approach for developing effects using the GPU shading languages.
It allows to combine various shader effects with each other
and with application internal shaders.
Our approach is relatively easy
to implement and allows the authors to directly use the existing GPU shading
languages.
We propose a number of extensions to the X3D,
an open standard for 3D data, to make our effects available for 3D
content authors. We have implemented our approach for the GLSL shading language.
</para>

</chapter>

<chapter id="acknowledgements">
<title>Acknowledgements</title>

<para>
%% A lot of people helped and encouraged the development of our VRML/X3D engine,
%% with it's rendering features and extensions. A big ``thank you''
%% goes to all of you.
</para>

<!--
\bibliographystyle{eg-alpha}
% \nocite{*}
\bibliography{compositing_shaders}
-->

</chapter>

</book>
